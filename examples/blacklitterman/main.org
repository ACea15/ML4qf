#+TITLE: Portfolio Construction using Black-Litterman Model and Factors
#+AUTHOR: Alvaro Cea
#+PROPERTY: header-args :tangle ./main.py :mkdirp yes
#+LATEX_HEADER: \usepackage[margin=1in]{geometry}
#+LATEX_HEADER: \usepackage{mathtools}

#+begin_comment
#+OPTIONS: toc:nil
#+LATEX_HEADER: \let\oldsection\section
#+LATEX_HEADER: \renewcommand{\section}{\clearpage\oldsection}
#+LATEX_HEADER: \let\oldsubsection\subsection
#+LATEX_HEADER: \renewcommand{\subsection}{\clearpage\oldsubsection}
#+end_comment

* House keeping :noexport:
#+begin_src elisp :results none :exports none
  (add-to-list 'org-structure-template-alist
  '("sp" . "src python :session py1"))
  (add-to-list 'org-structure-template-alist
  '("se" . "src elisp"))

  (setq org-confirm-babel-evaluate nil)
  (pyvenv-workon "ml4qf")
  (require 'org-tempo)
  (setq org-format-latex-options (plist-put org-format-latex-options :scale 2.0))
  (setq org-latex-pdf-process (list "latexmk -f -synctex=1 -pdf %f"))
  ;; (setq org-latex-pdf-process (list "latexmk -f -pdf -interaction=nonstopmode -output-directory=%o %f"))

#+end_src

#+begin_src python :session py1 :tangle yes :results none :exports none
  import pandas as pd
  import numpy as np
  import yfinance as yf
  import statsmodels.api as sm
  import getFamaFrenchFactors as gff
  import pathlib
  import datetime
  import importlib
  import ml4qf
  import ml4qf.collectors.financial_features as financial_features
  import ml4qf.collectors.financial_factors as financial_factors
  import ml4qf.collectors.financial_markets as financial_markets
  from ml4qf.predictors.model_stats import regression_OLS
  import ml4qf.predictors.model_stats as model_stats
  import ml4qf.portfolios.blacklitterman as bl
  import ml4qf.portfolios.optimization as optimization  
  from tabulate import tabulate
  import plotly.express as px
  import plotly.graph_objects as go
  import matplotlib.pyplot as plt
  from pandas.plotting import autocorrelation_plot
  import config
  importlib.reload(config)
  img_dir = pathlib.Path("./img/")
  #img_dir = img_dir0.absolute()
  img_dir.mkdir(parents=True, exist_ok=True)
  warnings.filterwarnings("ignore")
#+end_src

* Introduction
** Implemented computational tools and external libraries
- getFamaFrenchFactors
  gets data for fame french factors from the Kenneth French library
  https://pypi.org/project/getFamaFrenchFactors/
** Specifications:
For risk-free rate, 3M US Treasury from pandas FRED dataset/ECB website
rates for EUR/some small constant rate/zero rate – all are acceptable.
Use 2-3 year sample, which means > 500 daily returns.
** Index selection
The S&P 500 is considered a better reflection of the market’s performance across all sectors compared to the Nasdaq Composite and the Dow

#+begin_comment
#+CAPTION: Modal shape 1 
#+ATTR_LATEX: :width 0.75\textwidth
#+ATTR_ORG: :width 100
[[./img/polimi-M0.png]]
#+end_comment

* Theory
** Black-Litterman model
$$
VAR(X) = \frac{1}{n-1} \Sigma (xi - E(X))^2 
$$
$$
COV(X, Y) = \frac{1}{n-1} \Sigma (xi - E(X)) (yi - E(Y)) 
$$
$$
COR(X, Y) = \frac{COV(X, Y)}{(VAR(X)VAR(Y))^{0.5}}
$$


$$
\mu_{eq} = \lambda \Sigma w_{mkt}
$$

- $\mu_{eq}$ is the Implied Excess Equilibrium Return Vector 
- $\lambda$ is the risk aversion coefficient, $\lambda = \frac{E(\mu) - \mu_r}{\sigma^2}$
- $\Sigma$ is the covariance matrix of excess returns
- $w_{mkt}$ are market capitalization weights

$$
E[\mu_{bl}] = \left[(\tau \Sigma)^{-1} + P'\Omega^{-1}P\right]^{-1} \left[(\tau \Sigma)^{-1}\mu_{eq} + P'\Omega^{-1}Q\right]  
$$

- $E[\mu_{bl}]$: Posterior combined return vector ($N\times a$)
- $\tau$: error in views
- $P$: Matrix identifying assets involved in the views ($K\times N$)
- $Q$: View vector ($K\times 1$)
- $\Omega$: Diagonal covariance matrix with the errors expressed in the views ($N\times N$). 

Normal distributions:

- Prior equilibrium distribution: $N(\mu_{eq}, \tau \Sigma)$
- Views distribution: $N(Q, \Omega)$
- New combined return distribution: $N\left(E[\mu_{bl}], \left[(\tau \Sigma)^{-1} + P'\Omega^{-1}P\right]^{-1} \right)$
  
** Fama-French factors

It is one of the multi-factor models which is widely used in both academia and industry to estimate the excess return of an investment asset. It is an extension to Capital Asset Pricing Model (CAPM) by adding two additional factors apart from the market risk when estimating the excess returns of an asset. The three factors considered in this model are:

    Market factor (MKT) — Excess market return
    Size factor (SMB) — Excess return with a small market cap over those with a large market cap
    Value factor (HML) — Excess return of value stocks over growth stocks.

The Fama-French model is widely known as a stock market benchmark to evaluate investment performance.

$$
E[r_a] = \mu_a + \beta E[r_f]  + \epsilon_a
$$

$$
Var[r_a] = \mu_a + \beta r_f  + \epsilon_a
$$

$$
\Pi = w_a^{\top} r_a
$$

$$
Var(\Pi) = Var(r_a^{\top} w_a) = Var(r_a^{\top} w_a)
$$

** ARIMA model for time series
AutoRegressive Integrated Moving Average (ARIMA) statistical models are used 
AR: Autoregression. A model that uses the dependent relationship between an observation and some number of lagged observations.
I: Integrated. The use of differencing of raw observations (e.g. subtracting an observation from an observation at the previous time step) in order to make the time series stationary.
MA: Moving Average. A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.

Each of these components are explicitly specified in the model as a parameter. A standard notation is used of ARIMA(p,d,q) where the parameters are substituted with integer values to quickly indicate the specific ARIMA model being used.

The parameters of the ARIMA model are defined as follows:

- p: Number of lags in the observations that included in the model.
- d: Number of times differencing is applied to the observations.
- q: Size of moving average window.

** Optimisation

- Minimise Mean variance
- Maximize Sharpe ratio
- Hierarchical Risk Parity (HRP)   

* Results
** Portfolio and Factor analysis
:PROPERTIES:
:header-args: :session py1 :tangle yes :comments org
:END:
*** Asset selection
#+NAME: Load index 
#+begin_src python  :results none
  sp500 = financial_features.FinancialData("^GSPC",
                                           config.start_date_assets,
                                           config.end_date_assets)
  df_sp500 = sp500.df[['returns']].dropna()
#+end_src

#+NAME: Load portfolio and calculate market weights
#+begin_src python  :results none
  tickers_sp500 = ml4qf.collectors.scrap_tickers_index(config.index_weblist)
  df_tickers_sp500 = ml4qf.collectors.get_tickers_info(tickers_sp500,
                                                       config.info_sp500,
                                                       data_folder="./data",
                                                       name_family="sp500")
  df_tickers_sp500.dropna(inplace=True)
  df_tickers_filtered = ml4qf.utils.date_filter_lower(df_tickers_sp500,
                                                      'first_date',
                                                      date_lower=config.start_date_assets)
  df_tickers_filtered =  df_tickers_filtered.sort_values('marketCap',ascending=False)
  df_selected_tickers = ml4qf.collectors.select_assets(df_tickers_filtered,
                                                       config.ASSET_SELECTION_PCT,
                                                       config.ASSET_SELECTION_NAMES)
  # Market cap equilibrium weights
  w_mkt = df_selected_tickers.marketCap / df_selected_tickers.marketCap.sum()
  num_assets = len(df_selected_tickers)
  portfolios_path = pathlib.Path("./data/portfolios/")
  portfolios_path.mkdir(parents=True, exist_ok=True)
  portfolios_file = portfolios_path / ("_".join(df_selected_tickers.index))
  if not portfolios_file.is_file():
      df_selected_tickers.to_csv(portfolios_file)
  w_mkt = w_mkt.to_numpy()

  # Load assets returns
  fdc = financial_features.FinancialDataContainer(df_selected_tickers.index,
                                                  config.start_date_assets,
                                                  config.end_date_assets,
                                                  '1mo',
                                                  './data')
  df_assets = fdc.df.dropna()
  df_assets_train, df_assets_test = ml4qf.utils.split_df_date(
      df_assets,
      split_index=config.split_data_idx)
  asset_names = list(df_assets.columns)

#+end_src

#+NAME: Compute and show Data Frame, df_portfolio_summary
#+begin_src python :results raw :exports results
  df_portfolio_summary = df_selected_tickers.copy()
  #df_portfolio_summary = df_portfolio_summary.drop('first_date', axis=1)
  df_portfolio_summary['marketWeights'] = w_mkt
  df_portfolio_summary = df_portfolio_summary[['marketCap',
                                               'marketWeights',
                                               'sector']]
  tabulate(df_portfolio_summary,
           headers=df_portfolio_summary.columns,
           showindex=True,
           tablefmt='orgtbl')
#+end_src
#+ATTR_LATEX: :width 0.7\textwidth :environment longtable :caption  
#+RESULTS: Compute and show Data Frame, df_portfolio_summary
|      |   marketCap | marketWeights | sector                 |
|------+-------------+---------------+------------------------|
| JPM  | 4.46929e+11 |      0.544416 | Financial Services     |
| CVS  | 9.56394e+10 |      0.116501 | Healthcare             |
| ATVI | 7.18864e+10 |     0.0875667 | Communication Services |
| PH   | 5.41743e+10 |     0.0659911 | Industrials            |
| WELL | 4.24812e+10 |     0.0517475 | Real Estate            |
| YUM  |   3.733e+10 |     0.0454727 | Consumer Cyclical      |
| KR   | 3.53562e+10 |     0.0430683 | Consumer Defensive     |
| ATO  | 1.69743e+10 |     0.0206769 | Utilities              |
| EQT  | 1.59304e+10 |     0.0194052 | Energy                 |
| DXC  | 4.23124e+09 |    0.00515418 | Technology             |

*** Assets exploratory analysis

#+NAME: df_assets
#+begin_src python :session py1 :results raw :exports results
  tabulate(df_assets.iloc[:10],
           headers=asset_names,
           showindex=True,
           tablefmt='orgtbl')
#+end_src
#+ATTR_LATEX: :width 0.7\textwidth :environment longtable :caption  
#+RESULTS: df_assets
|                     |       AMZN |        CVS |        ATVI |         AFL |        PAYX |       WELL |          KR |         ATO |         GEN |         RHI |
|---------------------+------------+------------+-------------+-------------+-------------+------------+-------------+-------------+-------------+-------------|
| 2011-03-01 00:00:00 |  0.0394714 |  0.0381125 |  -0.0134892 |   -0.103296 |  -0.0666072 |  0.0042129 |   0.0467249 |  0.00827909 |   0.0282862 |  -0.0407523 |
| 2011-04-01 00:00:00 |  0.0870482 |  0.0553614 |   0.0373746 |   0.0646078 |   0.0420516 |  0.0253624 |   0.0141844 |   0.0231672 |   0.0598705 | -0.00882354 |
| 2011-05-01 00:00:00 | 0.00449422 |  0.0681943 |   0.0536028 |   -0.149493 |  -0.0125344 | -0.0107867 |    0.020979 |  -0.0441387 | -0.00508908 |   -0.090999 |
| 2011-06-01 00:00:00 |  0.0396562 | -0.0286895 |  -0.0258548 |  -0.0232266 |  -0.0489164 | -0.0142884 | -0.00080582 | -0.00299846 |  0.00869566 |  -0.0195865 |
| 2011-07-01 00:00:00 |  0.0881706 | -0.0327303 |   0.0136986 |  -0.0132819 |  -0.0810547 | 0.00667554 |  0.00282265 |  0.00541354 |  -0.0334686 |   0.0129485 |
| 2011-08-01 00:00:00 | -0.0327611 | -0.0121045 | 0.000844614 |   -0.181068 |  -0.0442791 | -0.0344828 |   -0.052674 |  0.00329048 |    -0.10021 |    -0.12637 |
| 2011-09-01 00:00:00 | 0.00464612 |  -0.064606 |  0.00421934 |  -0.0734359 |  -0.0226093 | -0.0816327 |  -0.0679117 |  -0.0324985 |  -0.0495627 |   -0.112876 |
| 2011-10-01 00:00:00 | -0.0125792 |  0.0815719 |     0.12521 |    0.290129 |    0.105044 |   0.125855 |   0.0555556 |   0.0576271 |   0.0435583 |    0.245523 |
| 2011-11-01 00:00:00 | -0.0993864 |  0.0690889 |  -0.0724421 |  -0.0365935 | -0.00102947 | -0.0478269 |           0 | -0.00320515 |  -0.0388007 |  0.00227013 |
| 2011-12-01 00:00:00 | -0.0997972 |  0.0499485 | -0.00805156 | -0.00414365 |   0.0343525 |  0.0869045 |   0.0448662 |  -0.0251389 |  -0.0428135 |   0.0743677 |

#+NAME: basket_returns
#+begin_src python :results value file  :exports results :var name=(org-element-property :name (org-element-context))
  fig1_path= img_dir / f'{name}.png'
  fig1 = px.line(df_assets, y=df_assets.keys())
  fig1.write_image(fig1_path)
  fig1_path #
#+end_src
#+CAPTION:  Asset's basket returns
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: basket_returns
[[file:./img/basket_returns.png]]

#+NAME: AssetsCorrelation
#+begin_src python :results value file  :exports results :var name=(org-element-property :name (org-element-context))
  fig1_path= img_dir / f'{name}.png'
  df_corr = df_assets.corr().round(2)
  fig1 = px.imshow(np.abs(df_corr))
  fig1.layout.height = 600
  fig1.layout.width = 600
  fig1.write_image(fig1_path)
  fig1_path #
#+end_src
#+CAPTION: Assets correlation
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: AssetsCorrelation
[[file:img/AssetsCorrelation.png]]

*** Factor collection
#+NAME: Load Fama and French 5 factors and Momentum factor  
#+begin_src python  :results none
  factor_names = financial_factors.get_factor_names(config.FACTORS)  
  df_factors0 = financial_factors.get_factors(config.FACTORS.keys(), 'm')
  df_factors =  ml4qf.utils.trim_df_date(df_factors0, start_date=config.start_date_factors,
                                         end_date=config.end_date_factors)
  df_factors_train, df_factors_test = ml4qf.utils.split_df_date(df_factors,
                                          split_index=config.split_data_idx)
#+end_src

#+NAME: Plot monthly Factors evolution 
#+begin_src python :results value file  :exports results :var name=(org-element-property :name (org-element-context))
  fig1_path= img_dir / f'{name}.png'
  fig1 = px.line(df_factors, y=factor_names)
  fig1.write_image(fig1_path)
  fig1_path # 
#+end_src
#+CAPTION: Factors evolution
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: Plot Factors evolution
[[file:img/Plot Factors evolution.png]]

#+NAME: RF rate evolution
#+begin_src python :results value file  :exports results :var name=(org-element-property :name (org-element-context))
  fig1_path= img_dir / f'{name}.png'
  fig1 = px.line(df_factors*12, y='RF')
  fig1.write_image(fig1_path)
  fig1_path #
#+end_src
#+CAPTION: (Annualised) risk-free rate evolution
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: RF rate evolution
[[file:img/RF rate evolution.png]]
*** Factor regression
#+NAME: Compute regression on assets returns vs factors
#+begin_src python :results none
  factor_models = financial_factors.factors_regression(factor_names,
                                                       df_factors_train,
                                                       df_assets_train,
                                                       regression_kernel=regression_OLS)
  alpha, beta = financial_factors.compute_factors_coeff(factor_models)
  factor_model = financial_factors.factor_lin_generator(alpha, beta)
#+end_src

#+NAME: Data Frame df_train_factors with alphas and betas
#+begin_src python  :results raw :exports results
  albe = np.vstack([alpha, beta]).T
  df_index = asset_names
  df_columns = ['alpha'] + factor_names
  df_train_factors = pd.DataFrame(albe, columns=df_columns, index=df_index)
  tabulate(df_train_factors, headers=df_columns, showindex=True, tablefmt='orgtbl')
#+end_src
#+ATTR_LATEX: :width 0.7\textwidth :environment longtable :caption
#+RESULTS: Data Frame df_train_factors with alphas and betas
|       |       alpha |   Mkt-RF |        SMB |       HML |        RMW |        CMA |        MOM |
|-------+-------------+----------+------------+-----------+------------+------------+------------|
| JPM   |  0.00445065 |  1.10652 |  -0.440155 |   1.40538 |   -1.24112 |  -0.824686 | -0.0246697 |
| CMCSA |   0.0013236 |  1.07818 |  -0.331769 | -0.109582 | -0.0620382 |   0.709663 |  -0.134245 |
| ADI   |  0.00284991 |   1.0065 |   0.470268 | 0.0107203 |   0.101693 |  -0.426269 |  -0.367543 |
| PH    |  -0.0023811 |  1.37354 |   0.543136 |  0.193102 |   0.399803 | -0.0483402 |  -0.298496 |
| DXCM  |   0.0303054 | 0.374555 |    1.41041 |  -1.78457 |  -0.936454 |    -1.1328 |  -0.356339 |
| TSCO  |  0.00455325 |  1.09016 |    0.55251 |  -0.63082 |   0.675689 |   0.972401 |  0.0849717 |
| AEE   |  0.00366709 | 0.476508 |  -0.136473 |  0.185148 |   0.372146 |   0.239563 |   0.481544 |
| CAG   |  -0.0011143 | 0.831855 |  -0.189053 | -0.238849 |   0.631176 |    1.16124 |  0.0633045 |
| CE    | 0.000539305 |  1.33332 | -0.0800048 |  0.681784 | -0.0613478 |  -0.528645 |  -0.129299 |
| FRT   | -0.00442393 | 0.574232 |   0.542634 |  0.401857 |   0.960915 |  -0.118601 |   0.184955 |

#+NAME: Summary of factors OLS
#+begin_src python :results output :exports results
  print(factor_models[df_assets.keys()[0]].summary())
#+end_src
#+ATTR_LATEX: :width 0.7\textwidth
#+CAPTION: Summary of factors OLS
#+RESULTS: Summary of factors OLS
#+begin_example
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.763
Model:                            OLS   Adj. R-squared:                  0.750
Method:                 Least Squares   F-statistic:                     56.87
Date:                Tue, 15 Aug 2023   Prob (F-statistic):           6.38e-31
Time:                        11:34:23   Log-Likelihood:                 218.93
No. Observations:                 113   AIC:                            -423.9
Df Residuals:                     106   BIC:                            -404.8
Df Model:                           6                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          0.0045      0.004      1.211      0.229      -0.003       0.012
x1             1.1065      0.101     10.935      0.000       0.906       1.307
x2            -0.4402      0.174     -2.525      0.013      -0.786      -0.094
x3             1.4054      0.179      7.836      0.000       1.050       1.761
x4            -1.2411      0.245     -5.070      0.000      -1.726      -0.756
x5            -0.8247      0.287     -2.877      0.005      -1.393      -0.256
x6            -0.0247      0.124     -0.199      0.843      -0.270       0.221
==============================================================================
Omnibus:                        3.890   Durbin-Watson:                   2.265
Prob(Omnibus):                  0.143   Jarque-Bera (JB):                3.745
Skew:                           0.235   Prob(JB):                        0.154
Kurtosis:                       3.758   Cond. No.                         91.5
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
#+end_example

#+NAME: Compute factor model prediction
#+begin_src python :results none
  # prediction on test data
  returns_pred = factor_model(df_factors_test[factor_names].to_numpy())
  df_returns_pred = pd.DataFrame(returns_pred,
                                 columns=asset_names,
                                 index=df_assets_test.index)
  # prediction on training data
  returns_predt = factor_model(df_factors_train[factor_names].to_numpy())
  df_returns_predt = pd.DataFrame(returns_predt,
                                 columns=asset_names,
                                 index=df_assets_train.index)

#+end_src

*** Factors backtesting
#+begin_comment
#+NAME: predicted_returns
#+begin_src python :var i_asset=0 name=(org-element-property :name (org-element-context))
  i_asset = i_asset
  i_name = asset_names[i_asset]
  fig1_path= img_dir / f'{name}{i_name}.png'
  fig1 = go.Figure()
  fig1.add_trace(go.Scatter(
      x=df_assets_test.index,
      y=df_assets_test.iloc[:, i_asset] - df_factors_test.RF.to_numpy(),
      mode='lines+markers',
      name=f"{i_name} real"))
  fig1.add_trace(go.Scatter(
      x=df_assets_test.index,
      y=df_returns_pred[i_name],
      mode='lines',
      name=f"{i_name} pred."))

  #px.line(df_returns_pred['GOOGL'], y=df_returns_pred.keys()[0])

  fig1.write_image(fig1_path)
  str(fig1_path)
#+end_src

#+NAME: predicted_returns0
#+begin_src python :noweb eval :results value file  :exports results
  fig_path = "<<predicted_returns(i_asset=0, name="predicted_returns_")>>"
  fig_path
#+end_src
#+CAPTION:  Backtesting factor approximation on Google asset
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: predicted_returns0
#+end_comment
#+NAME: Function to plot returns from factor model
#+begin_src python :results none
  def plot_rets_fromfactors(df_assets,
                            df_factors,
                            df_returns_pred,
                            i_asset,
                            name):

      i_name = asset_names[i_asset]
      fig1_path= img_dir / f'{name}{i_name}.png'
      fig1 = go.Figure()
      fig1.add_trace(go.Scatter(
          x=df_assets.index,
          y=df_assets.iloc[:, i_asset] - df_factors.RF.to_numpy(),
          mode='lines+markers',
          name=f"{i_name} real"))
      fig1.add_trace(go.Scatter(
          x=df_assets.index,
          y=df_returns_pred[i_name],
          mode='lines',
          name=f"{i_name} pred."))

      #px.line(df_returns_pred['GOOGL'], y=df_returns_pred.keys()[0])

      fig1.write_image(fig1_path)
      return str(fig1_path)

#+end_src

#+NAME: predicted_returns0
#+begin_src python :noweb eval :results value file  :exports results
  fig1_path = plot_rets_fromfactors(df_assets_test,
                                   df_factors_test,
                                   df_returns_pred,
                                   i_asset=1, name="predicted_testingreturns_")
  fig1_path #
#+end_src
#+CAPTION:  Backtesting factor approaximation on Google asset
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: predicted_returns0
[[file:img/predicted_testingreturns_CMCSA.png]]

#+NAME: predicted_returns0traing
#+begin_src python :noweb eval :results value file  :exports results
  fig1_path = plot_rets_fromfactors(df_assets_train,
                                   df_factors_train,
                                   df_returns_predt,
                                   i_asset=1, name="predicted_trainingreturns_")
  fig1_path #
#+end_src
#+CAPTION:  Backtesting factor approaximation on Google asset
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: predicted_returns0traing
[[file:img/predicted_trainingreturns_CMCSA.png]]

** Generation of asset views
:PROPERTIES:
:header-args: :session py1 :tangle yes :comments org
:END:
*** ARIMA model construction
#+NAME: arima_autocorrelation
#+begin_src python :results value file  :exports results :var name=(org-element-property :name (org-element-context))
  fig1_path= img_dir / f'{name}.png'
  fig = plt.figure()
  ax = autocorrelation_plot(df_train_factors['Mkt-RF'])
  #ax.set_title("bleh")
  #ax.set_xlabel("xlabel")
  #ax.plot(x, y, 'r--')
  fig.savefig(fig1_path)
  fig1_path
#+end_src

#+RESULTS: arima_autocorrelation
[[file:img/arima_autocorrelation.png]]

#+begin_src python :results none
  Xtrain = df_factors_train[factor_names].to_numpy()
  Xtest = df_factors_test[factor_names].to_numpy()
  index_train = df_factors_train.index
  index_test = df_factors_test.index
  arima_parameters = {'Mkt-RF': (14,2,10),
                      'SMB': (2,1,0),
                      'HML': (2,1,0),
                      'RMW': (2,1,0),
                      'CMA': (3,2,0),
                      'MOM': (2,1,0)
                      }
  model_sett = dict(enforce_stationarity=False,
                    enforce_invertibility=False) 
  arima_train_models = model_stats.arima_fit(Xtrain,
                                             factor_names,
                                             arima_parameters,
                                             model_sett=model_sett)
  df_arimatrain, df_arimatest = model_stats.arima_build_pred(arima_train_models,
                                                             Xtrain,
                                                             Xtest,
                                                             factor_names,
                                                             index_train,
                                                             index_test)  
#+end_src

#+begin_src python :results output
  print(arima_train_models['Mkt-RF'].summary())
#+end_src

#+RESULTS:
#+begin_example
                               SARIMAX Results                                
==============================================================================
Dep. Variable:                      y   No. Observations:                  113
Model:               ARIMA(14, 2, 10)   Log Likelihood                 185.942
Date:                Tue, 15 Aug 2023   AIC                           -321.885
Time:                        13:43:35   BIC                           -257.517
Sample:                             0   HQIC                          -295.858
                                - 113                                         
Covariance Type:                  opg                                         
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
ar.L1         -2.5725      0.630     -4.084      0.000      -3.807      -1.338
ar.L2         -4.0994      1.437     -2.852      0.004      -6.916      -1.282
ar.L3         -5.3448      2.115     -2.527      0.012      -9.491      -1.199
ar.L4         -6.3109      2.596     -2.431      0.015     -11.399      -1.222
ar.L5         -7.0200      2.870     -2.446      0.014     -12.646      -1.394
ar.L6         -7.2300      3.045     -2.374      0.018     -13.199      -1.261
ar.L7         -6.6472      3.097     -2.146      0.032     -12.718      -0.576
ar.L8         -5.5848      2.936     -1.902      0.057     -11.339       0.169
ar.L9         -4.4234      2.612     -1.693      0.090      -9.543       0.696
ar.L10        -3.1031      2.194     -1.414      0.157      -7.404       1.197
ar.L11        -1.8092      1.745     -1.037      0.300      -5.230       1.612
ar.L12        -0.9664      1.296     -0.746      0.456      -3.506       1.573
ar.L13        -0.5024      0.788     -0.638      0.524      -2.047       1.042
ar.L14        -0.2345      0.305     -0.768      0.443      -0.833       0.364
ma.L1          0.5390      0.574      0.938      0.348      -0.587       1.665
ma.L2          0.0026      0.498      0.005      0.996      -0.973       0.978
ma.L3         -0.4013      0.366     -1.096      0.273      -1.119       0.316
ma.L4         -0.5210      0.461     -1.130      0.259      -1.425       0.383
ma.L5          0.0350      0.539      0.065      0.948      -1.020       1.090
ma.L6         -0.1929      0.402     -0.480      0.631      -0.980       0.595
ma.L7         -0.6095      0.345     -1.769      0.077      -1.285       0.066
ma.L8         -0.0968      0.346     -0.279      0.780      -0.776       0.582
ma.L9          0.1733      0.338      0.513      0.608      -0.489       0.836
ma.L10         0.1687      0.253      0.667      0.505      -0.327       0.664
sigma2         0.0011      0.000      2.897      0.004       0.000       0.002
===================================================================================
Ljung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):                 1.82
Prob(Q):                              0.99   Prob(JB):                         0.40
Heteroskedasticity (H):               2.55   Skew:                            -0.29
Prob(H) (two-sided):                  0.01   Kurtosis:                         3.34
===================================================================================

Warnings:
[1] Covariance matrix calculated using the outer product of gradients (complex-step).
#+end_example

*** ARIMA model prediction

#+NAME: ARIMA_Mkt-RF_train
#+begin_src python :results value file :exports results :var name=(org-element-property :name (org-element-context))
  fig1_path= img_dir / f'{name}.png'
  fig1 = px.line(df_arimatrain, y=['Mkt-RF','Mkt-RF_pred'])
  fig1.write_image(fig1_path)
  fig1_path #

#+end_src
#+CAPTION: d
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: ARIMA_Mkt-RF_train
[[file:img/ARIMA_Mkt-RF_train.png]]

#+NAME: ARIMA_Mkt-RF_test
#+begin_src python :results value file :exports results :var name=(org-element-property :name (org-element-context))
  fig1_path= img_dir / f'{name}.png'
  fig1 = px.line(df_arimatest, y=['Mkt-RF','Mkt-RF_pred'])
  fig1.write_image(fig1_path)
  fig1_path #

#+end_src
#+CAPTION: d
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: ARIMA_Mkt-RF_test
[[file:img/ARIMA_Mkt-RF_test.png]]

*** ARIMA backtesting

#+begin_src python :results none
  # prediction on test data
  fnames_prediction = [k for k in df_arimatrain.columns if "_pred" in k]
  asset_names_pred = [k + '_pred' for k in asset_names]
  returns_arimapred_train = factor_model(df_arimatrain[fnames_prediction].to_numpy())
  df_arimapred_train = pd.DataFrame(returns_arimapred_train,
                                    columns=asset_names_pred,
                                    index=df_assets_train.index)
  df_arimaasset_train = df_arimapred_train.join(df_assets_train).dropna()
  # prediction on training data
  returns_arimapred_test = factor_model(df_arimatest[fnames_prediction].to_numpy())
  df_arimapred_test = pd.DataFrame(returns_arimapred_test,
                                    columns=asset_names_pred,
                                    index=df_assets_test.index)
  df_arimaasset_test = df_arimapred_test.join(df_assets_test).dropna()
  # prediction on training data
  df_arimatest_profits = ml4qf.utils.profit_portfolio(
      df_arimaasset_test,
      {k: 1. for k in df_arimaasset_test.columns})
#+end_src


** Black-Litterman based portfolio
:PROPERTIES:
:header-args: :session py1 :tangle yes :comments org
:END:

*** Prior and posterior returns construction

#+NAME: Calculate Covariance of excess returns
#+begin_src python :results none
  df_Sigma_factors = df_factors[factor_names].cov()
  df_Sigma_factors_train = df_factors_train[factor_names].cov()
  df_Sigma_factors_test = df_factors_test[factor_names].cov()
  Sigma_factors = df_Sigma_factors.to_numpy()
  Sigmainv_factors = np.linalg.inv(Sigma_factors)
  Sigma_factors_train = df_Sigma_factors_train.to_numpy()
  Sigmainv_factors_train = np.linalg.inv(Sigma_factors_train)
  Sigma_factors_test = df_Sigma_factors_test.to_numpy()
  Sigmainv_factors_test = np.linalg.inv(Sigma_factors_test)
  #####
  df_Sigma_assets = df_assets.cov()
  df_Sigma_assets_train = df_assets_train.cov()
  df_Sigma_assets_test = df_assets_test.cov()
  Sigma_assets = df_Sigma_assets.to_numpy()
  Sigmainv_assets = np.linalg.inv(Sigma_assets)
  Sigma_assets_train = df_Sigma_assets_train.to_numpy()
  Sigmainv_assets_train = np.linalg.inv(Sigma_assets_train)
  Sigma_assets_test = df_Sigma_assets_test.to_numpy()
  Sigmainv_assets_test = np.linalg.inv(Sigma_assets_test)
  #####
  Sigma_4mfactors = beta.T @ Sigma_factors @ beta
  Sigmainv_4mfactors = np.linalg.inv(Sigma_4mfactors)
  Sigma_4mfactors_train = beta.T @ Sigma_factors_train @ beta
  Sigmainv_4mfactors_train = np.linalg.inv(Sigma_4mfactors_train)
  Sigma_4mfactors_test = beta.T @ Sigma_factors_test @ beta
  Sigmainv_4mfactors_test = np.linalg.inv(Sigma_4mfactors_test)

#+end_src

#+NAME: Compute equilibrium returns 
#+begin_src python :results none
  f_mu = lambda l, S, w: l * S @ w
  mu_mkt_assets = f_mu(config.lambda_mkt, Sigma_assets, w_mkt)
  mu_mkt_4mfactors = f_mu(config.lambda_mkt, Sigma_4mfactors, w_mkt)
  optimization.mean_variance_opt(mu_mkt_assets)
#+end_src

#+NAME: Black-Litterman initialisation
#+begin_src python :results none
  pf_trustee = bl.BlackLitterman(Sigma, w_mkt, config.lambda_mkt[0])
  pf_ = bl.BlackLitterman(Sigma, w_mkt, config.lambda_mkt[1])
  pf_trustee = bl.BlackLitterman(Sigma, w_mkt, config.lambda_mkt[2])
#+end_src

*** Covariance treatment
*** Portfolio weights optimisation

#+NAME: Calculate Covariance of factors
#+begin_src python :results none

  lmb_p = config.lambda_portfolio[2]
  w_opt0 = optimization.mean_variance_opt(mu_mkt_assets,            
                                          Sigmainv_assets,          
                                          lmb_p)

  x0 = 1. / num_assets * np.ones(num_assets)
  args = (mu_mkt_assets,            
          Sigma_assets,          
          lmb_p)
  res0 = optimization.scipy_minimize("mean_variance",
                                     x0,
                                     method_name='SLSQP',
                                     args=args,
                                     options=dict(maxiter=200,
                                                  ftol=1e-12))

#+end_src

#+NAME: Compute porfolio weights frontier
#+begin_src python :results none

  lmb_p = config.lambda_portfolio[2]

  x0 = 1. / num_assets * np.ones(num_assets)
  args = (mu_mkt_assets*12,
          Sigma_assets,
          0.15)
  cons_sett = dict(eq_rets=dict(type="eq"),
                   eq_weights1=dict(type="eq"),
                   ieq_weights0=dict(type="ineq")
                   )
  res1 = optimization.scipy_minimize("variance",
                                     x0,
                                     method_name='SLSQP',
                                     args=args,
                                     cons_sett=cons_sett,
                                     options=dict(maxiter=200,
                                                  ftol=1e-12))

  print(np.dot(res1.x, Sigma_assets @ res1.x)**0.5 * 12**0.5 * 100)
  print(res1.fun**0.5 * 12**0.5 * 100)
  print(sum(res1.x))
  print(res1.x)
#+end_src

#+NAME: Function to build portfolios weights
#+begin_src python :results none

  def build_portfolio_weights(mu_targetlist,
                              x0,
                              mu_portfolio,
                              Sigma_portfolio,
                              cons_sett,
                              annualise=12):

      res_list = list()
      for mu_i in mu_targetlist:
          args = (mu_portfolio * annualise, # annualised
                  Sigma_portfolio,
                  mu_i)
          res = optimization.scipy_minimize("variance",
                                             x0,
                                             method_name='SLSQP',
                                             args=args,
                                             cons_sett=cons_sett,
                                             options=dict(maxiter=200,
                                                          ftol=1e-12))
          res_list.append(res)
      return res_list

#+end_src

#+NAME: Function to compute weights vs volatility for target returns
#+begin_src python :results none

  def build_df_weightsvol(assets,
                          mu_targetlist,
                          x0,
                          lmb_p,
                          mu_portfolio,
                          Sigma_portfolio,
                          annualise=12):

      # constraints: returns equal to a number given in mu_targetlist,
      # weights equal to 1, and all weights greater than 0
      cons_sett = dict(eq_rets=dict(type="eq"),
                       eq_weights1=dict(type="eq"),
                       ieq_weights0=dict(type="ineq")
                       )

      res_list = build_portfolio_weights(mu_targetlist,
                                         x0,
                                         mu_portfolio,
                                         Sigma_portfolio,
                                         cons_sett,
                                         annualise
                                         )


      weights = np.array([ri.x for ri in res_list])
      Weights = weights.flatten()
      # anualise vols
      vols=[((ri.fun) * annualise)**0.5 for ri in res_list]
      Vols = [vi for vi in vols for i in range(len(assets))]
      Assets = [k for i in range(len(vols)) for k in assets]
      df_weights_vols = pd.DataFrame(dict(weights=Weights,
                                          vols=Vols,
                                          assets=Assets
                                          ))
      return df_weights_vols
#+end_src

#+NAME: df with portfolios weights
#+begin_src python :results none

  lmb_p = config.lambda_portfolio[2]
  x0 = 1. / num_assets * np.ones(num_assets)
  mu_targetlist = np.linspace(4,18,16) * 1e-2
  df_weights_vols = build_df_weightsvol(asset_names, mu_targetlist, x0, lmb_p,
                                        mu_mkt_assets,
                                        Sigma_assets)

#+end_src

#+NAME: Weights_Composition
#+begin_src python :results value file  :exports results :var name=(org-element-property :name (org-element-context))
  fig1_path= img_dir / f'{name}.png'
  fig1 = px.area(df_weights_vols, x="vols", y="weights", color="assets",
                #pattern_shape_sequence=[".", "x", "+"],              
                pattern_shape="assets"
                )
  fig1.write_image(fig1_path)
  fig1_path
#+end_src

#+RESULTS: Weights_Composition
[[file:img/Weights_Composition.png]]


#+begin_src python :results none
  weights_sol = {k: res1.x[i] for i, k in enumerate(asset_names)}
  df_profits_sol = ml4qf.utils.profit_portfolio(df_assets_test, weights_sol)
  weights_naive = {k: x0[i] for i, k in enumerate(asset_names)}  
  df_profits_naive = ml4qf.utils.profit_portfolio(df_assets_test, weights_naive)

  df_profits = pd.DataFrame(np.array([df_profits_sol.sum(axis=1).to_numpy(),
                             df_profits_naive.sum(axis=1).to_numpy()]).T,
                             columns=['Opt', 'Naive'], index=df_profits_sol.index)
#+end_src

#+NAME: P&L_plot
#+begin_src python :results value file  :exports results :var name=(org-element-property :name (org-element-context))
  fig1_path= img_dir / f'{name}.png'
  fig1 = px.line(df_profits, y=['Opt', 'Naive'], markers=True)
  fig1.write_image(fig1_path)
  fig1_path
#+end_src

#+RESULTS: P&L_plot
[[file:img/P&L_plot.png]]

*** Analysis and discussion

- active risk (Table 6)
*** Performance comparison



#+LaTeX: \appendix
* Code execution
The codes herein have been tested in linux (Ubuntu 22 and Centos 8) and in MacOs


** Testing
