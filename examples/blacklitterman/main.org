#+TITLE: Portfolio Construction using Black-Litterman Model and Factors
#+AUTHOR: Alvaro Cea
#+PROPERTY: header-args :tangle ./main.py :mkdirp yes
#+LATEX_HEADER: \usepackage[margin=1in]{geometry}
#+LATEX_HEADER: \usepackage{mathtools}

#+begin_comment
#+OPTIONS: toc:nil
#+LATEX_HEADER: \let\oldsection\section
#+LATEX_HEADER: \renewcommand{\section}{\clearpage\oldsection}
#+LATEX_HEADER: \let\oldsubsection\subsection
#+LATEX_HEADER: \renewcommand{\subsection}{\clearpage\oldsubsection}
#+end_comment

* House keeping :noexport:
#+begin_src elisp :results none :exports none
  (add-to-list 'org-structure-template-alist
  '("sp" . "src python :session py1"))
  (add-to-list 'org-structure-template-alist
  '("se" . "src elisp"))

  (setq org-confirm-babel-evaluate nil)
  (pyvenv-workon "ml4qf")
  (require 'org-tempo)
  (setq org-format-latex-options (plist-put org-format-latex-options :scale 2.0))
  (setq org-latex-pdf-process (list "latexmk -f -synctex=1 -pdf %f"))
  ;; (setq org-latex-pdf-process (list "latexmk -f -pdf -interaction=nonstopmode -output-directory=%o %f"))

#+end_src

#+begin_src python :session py1 :tangle yes :results none :exports none
  import pandas as pd
  import numpy as np
  import yfinance as yf
  import statsmodels.api as sm
  import getFamaFrenchFactors as gff
  import pathlib
  import datetime
  import importlib
  import ml4qf
  import ml4qf.collectors.financial_features as financial_features
  import ml4qf.collectors.financial_factors as financial_factors
  import ml4qf.collectors.financial_markets as financial_markets
  from ml4qf.predictors.model_stats import regression_OLS
  import ml4qf.predictors.model_stats as model_stats
  import ml4qf.portfolios.blacklitterman as bl
  import ml4qf.portfolios.optimization as optimization  
  from tabulate import tabulate
  import plotly.express as px
  import plotly.graph_objects as go
  import matplotlib.pyplot as plt
  import collections
  from pandas.plotting import autocorrelation_plot
  import config
  importlib.reload(config)
  img_dir = pathlib.Path("./img/")
  #img_dir = img_dir0.absolute()
  img_dir.mkdir(parents=True, exist_ok=True)
  import warnings
  warnings.filterwarnings("ignore")
#+end_src

* Introduction
** Implemented computational tools and external libraries
- getFamaFrenchFactors
  gets data for fame french factors from the Kenneth French library
  https://pypi.org/project/getFamaFrenchFactors/
** Specifications:
For risk-free rate, 3M US Treasury from pandas FRED dataset/ECB website
rates for EUR/some small constant rate/zero rate – all are acceptable.
Use 2-3 year sample, which means > 500 daily returns.
** Index selection
The S&P 500 is considered a better reflection of the market’s performance across all sectors compared to the Nasdaq Composite and the Dow

#+begin_comment
#+CAPTION: Modal shape 1 
#+ATTR_LATEX: :width 0.75\textwidth
#+ATTR_ORG: :width 100
[[./img/polimi-M0.png]]
#+end_comment

* Theory
** Black-Litterman model
$$
VAR(X) = \frac{1}{n-1} \Sigma (xi - E(X))^2 
$$
$$
COV(X, Y) = \frac{1}{n-1} \Sigma (xi - E(X)) (yi - E(Y)) 
$$
$$
COR(X, Y) = \frac{COV(X, Y)}{(VAR(X)VAR(Y))^{0.5}}
$$


$$
\mu_{eq} = \lambda \Sigma w_{mkt}
$$

- $\mu_{eq}$ is the Implied Excess Equilibrium Return Vector 
- $\lambda$ is the risk aversion coefficient, $\lambda = \frac{E(\mu) - \mu_r}{\sigma^2}$
- $\Sigma$ is the covariance matrix of excess returns
- $w_{mkt}$ are market capitalization weights

$$
E[\mu_{bl}] = \left[(\tau \Sigma)^{-1} + P'\Omega^{-1}P\right]^{-1} \left[(\tau \Sigma)^{-1}\mu_{eq} + P'\Omega^{-1}Q\right]  
$$

- $E[\mu_{bl}]$: Posterior combined return vector ($N\times a$)
- $\tau$: error in views
- $P$: Matrix identifying assets involved in the views ($K\times N$)
- $Q$: View vector ($K\times 1$)
- $\Omega$: Diagonal covariance matrix with the errors expressed in the views ($N\times N$). 

Normal distributions:

- Prior equilibrium distribution: $N(\mu_{eq}, \tau \Sigma)$
- Views distribution: $N(Q, \Omega)$
- New combined return distribution: $N\left(E[\mu_{bl}], \left[(\tau \Sigma)^{-1} + P'\Omega^{-1}P\right]^{-1} \right)$
  
** Fama-French factors

It is one of the multi-factor models which is widely used in both academia and industry to estimate the excess return of an investment asset. It is an extension to Capital Asset Pricing Model (CAPM) by adding two additional factors apart from the market risk when estimating the excess returns of an asset. The three factors considered in this model are:

    Market factor (MKT) — Excess market return
    Size factor (SMB) — Excess return with a small market cap over those with a large market cap
    Value factor (HML) — Excess return of value stocks over growth stocks.

The Fama-French model is widely known as a stock market benchmark to evaluate investment performance.

$$
E[r_a] = \mu_a + \beta E[r_f]  + \epsilon_a
$$

$$
Var[r_a] = \mu_a + \beta r_f  + \epsilon_a
$$

$$
\Pi = w_a^{\top} r_a
$$

$$
Var(\Pi) = Var(r_a^{\top} w_a) = Var(r_a^{\top} w_a)
$$

** ARIMA model for time series
AutoRegressive Integrated Moving Average (ARIMA) statistical models are used 
AR: Autoregression. A model that uses the dependent relationship between an observation and some number of lagged observations.
I: Integrated. The use of differencing of raw observations (e.g. subtracting an observation from an observation at the previous time step) in order to make the time series stationary.
MA: Moving Average. A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.

Each of these components are explicitly specified in the model as a parameter. A standard notation is used of ARIMA(p,d,q) where the parameters are substituted with integer values to quickly indicate the specific ARIMA model being used.

The parameters of the ARIMA model are defined as follows:

- p: Number of lags in the observations that included in the model.
- d: Number of times differencing is applied to the observations.
- q: Size of moving average window.

** Optimisation

- Minimise Mean variance
- Maximize Sharpe ratio
- Hierarchical Risk Parity (HRP)   

* Results
** Portfolio and Factor analysis
:PROPERTIES:
:header-args: :session py1 :tangle yes
:END:
*** Asset selection
#+NAME: Load index SP500
#+begin_src python :results none
  # Load index SP500
  sp500 = financial_features.FinancialData("^GSPC",
                                           config.start_date_assets,
                                           config.end_date_assets,
                                           DATA_FOLDER="./data")
  df_sp500 = sp500.df[['returns']].dropna()
#+end_src

#+NAME: Load portfolio and calculate market weights
#+begin_src python :results none
  # Load portfolio and calculate market weights
  tickers_sp500 = ml4qf.collectors.scrap_tickers_index(config.index_weblist)
  df_tickers_sp500 = ml4qf.collectors.get_tickers_info(tickers_sp500,
                                                       config.info_sp500,
                                                       data_folder="./data",
                                                       name_family="sp500")
  df_tickers_sp500.dropna(inplace=True)
  df_tickers_filtered = ml4qf.utils.date_filter_lower(df_tickers_sp500,
                                                      'first_date',
                                                      date_lower=config.start_date_assets)
  df_tickers_filtered =  df_tickers_filtered.sort_values('marketCap',ascending=False)
  df_selected_tickers = ml4qf.collectors.select_assets(df_tickers_filtered,
                                                       config.ASSET_SELECTION_PCT,
                                                       config.ASSET_SELECTION_NAMES)
  # Market cap equilibrium weights
  w_mkt = df_selected_tickers.marketCap / df_selected_tickers.marketCap.sum()
  num_assets = len(df_selected_tickers)
  portfolios_path = pathlib.Path("./data/portfolios/")
  portfolios_path.mkdir(parents=True, exist_ok=True)
  portfolios_file = portfolios_path / ("_".join(df_selected_tickers.index))
  if not portfolios_file.is_file():
      df_selected_tickers.to_csv(portfolios_file)
  w_mkt = w_mkt.to_numpy()

  # Load assets returns
  fdc = financial_features.FinancialDataContainer(df_selected_tickers.index,
                                                  config.start_date_assets,
                                                  config.end_date_assets,
                                                  '1mo',
                                                  './data')
  df_assets = fdc.df.dropna()
  df_assets_train, df_assets_test = ml4qf.utils.split_df_date(
      df_assets,
      split_index=config.split_data_idx)
  asset_names = list(df_assets.columns)

#+end_src

#+NAME: Compute and show Data Frame, df_portfolio_summary
#+begin_src python :results raw :exports results :tangle no
  # Compute Data Frame df_portfolio_summary
  df_portfolio_summary = df_selected_tickers.copy()
  #df_portfolio_summary = df_portfolio_summary.drop('first_date', axis=1)
  df_portfolio_summary['marketWeights'] = w_mkt
  df_portfolio_summary = df_portfolio_summary[['marketCap',
                                               'marketWeights',
                                               'sector']]
  tabulate(df_portfolio_summary,
           headers=df_portfolio_summary.columns,
           showindex=True,
           tablefmt='orgtbl')
#+end_src
#+ATTR_LATEX: :width 0.7\textwidth :environment longtable :caption  
#+RESULTS: Compute and show Data Frame, df_portfolio_summary
|      |   marketCap | marketWeights | sector                 |
|------+-------------+---------------+------------------------|
| JPM  | 4.46929e+11 |      0.544416 | Financial Services     |
| CVS  | 9.56394e+10 |      0.116501 | Healthcare             |
| ATVI | 7.18864e+10 |     0.0875667 | Communication Services |
| PH   | 5.41743e+10 |     0.0659911 | Industrials            |
| WELL | 4.24812e+10 |     0.0517475 | Real Estate            |
| YUM  |   3.733e+10 |     0.0454727 | Consumer Cyclical      |
| KR   | 3.53562e+10 |     0.0430683 | Consumer Defensive     |
| ATO  | 1.69743e+10 |     0.0206769 | Utilities              |
| EQT  | 1.59304e+10 |     0.0194052 | Energy                 |
| DXC  | 4.23124e+09 |    0.00515418 | Technology             |

*** Assets exploratory analysis

#+NAME: df_assets
#+begin_src python :session py1 :results raw :exports results :tangle no
  tabulate(df_assets.iloc[:10],
           headers=asset_names,
           showindex=True,
           tablefmt='orgtbl')
#+end_src
#+ATTR_LATEX: :width 0.7\textwidth :environment longtable :caption  
#+RESULTS: df_assets
|                     |        JPM |        CVS |       ATVI |         PH |        WELL |        YUM |          KR |        ATO |        EQT |        DXC |
|---------------------+------------+------------+------------+------------+-------------+------------+-------------+------------+------------+------------|
| 2000-03-01 00:00:00 |  0.0949765 |  0.0732143 | -0.0492617 |   0.139655 |   -0.100402 |   0.166667 |    0.175732 | -0.0437956 |   0.187086 | 0.00396511 |
| 2000-04-01 00:00:00 |   -0.17276 |    0.15807 |  -0.481865 |   0.125567 |    0.138393 |  0.0905433 |   0.0569395 | -0.0305344 |  0.0348675 |  0.0308057 |
| 2000-05-01 00:00:00 |  0.0355287 |          0 | -0.0099994 |  -0.103495 |  0.00784314 |  -0.134686 |   0.0707071 |   0.153543 |  0.0727763 |   0.174713 |
| 2000-06-01 00:00:00 | -0.0748954 | -0.0804598 |  0.0505057 |  -0.178411 |   0.0126459 | -0.0362472 |    0.110063 | -0.0435154 | -0.0298367 |  -0.220483 |
| 2000-07-01 00:00:00 |  0.0814111 |    -0.0125 |   0.346154 |  0.0383212 |    0.106628 |  -0.141593 |  -0.0623229 |    0.17752 |  0.0786662 |  -0.171548 |
| 2000-08-01 00:00:00 |   0.121706 |  -0.059731 |        0.6 | -0.0210896 |  0.00347222 |   0.201675 |   0.0974321 | 0.00606061 |  0.0816327 |   0.277778 |
| 2000-09-01 00:00:00 |  -0.173378 |    0.24695 |  0.0714283 | -0.0305206 |   -0.017301 |  0.0509384 | -0.00619416 | -0.0060241 |   0.125694 | -0.0608695 |
| 2000-10-01 00:00:00 |  -0.014885 |    0.14305 | -0.0791664 |   0.225926 | -0.00352113 | -0.0204083 |           0 |   0.121212 | -0.0850382 |  -0.151515 |
| 2000-11-01 00:00:00 |   -0.18956 |  0.0743802 |  -0.248869 | -0.0649546 |  -0.0459364 |        0.2 |    0.174515 |  0.0864865 |  -0.038793 |  0.0823413 |
| 2000-12-01 00:00:00 |   0.232203 |  0.0538462 |   0.457832 |   0.140549 |   -0.037037 | -0.0833332 |   0.0212264 | -0.0298507 |   0.197309 |   -0.11824 |

#+NAME: basket_returns
#+begin_src python :results value file  :exports results :var name=(org-element-property  :name (org-element-context))
  # Plot basket_returns
  fig1_path= img_dir / f'{name}.png'
  fig1 = px.line(df_assets, y=df_assets.keys())
  fig1.write_image(fig1_path)
  fig1_path #
#+end_src

#+CAPTION:  Asset's basket returns
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: basket_returns
[[file:img/basket_returns.png]]


#+NAME: AssetsCorrelation
#+begin_src python :results value file  :exports results :var name=(org-element-property :name (org-element-context))
  # Plot AssetsCorrelation
  fig1_path= img_dir / f'{name}.png'
  df_corr = df_assets.corr().round(2)
  fig1 = px.imshow(np.abs(df_corr))
  fig1.layout.height = 600
  fig1.layout.width = 600
  fig1.write_image(fig1_path)
  fig1_path #
#+end_src
#+CAPTION: Assets correlation
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: AssetsCorrelation
[[file:img/AssetsCorrelation.png]]

*** Factor collection
#+NAME: Load Fama and French 5 factors and Momentum factor  
#+begin_src python  :results none
  # Load Fama and French 5 factors and Momentum factor
  factor_names = financial_factors.get_factor_names(config.FACTORS)  
  df_factors0 = financial_factors.get_factors(config.FACTORS.keys(), 'm')
  df_factors =  ml4qf.utils.trim_df_date(df_factors0, start_date=config.start_date_factors,
                                         end_date=config.end_date_factors)
  df_factors_train, df_factors_test = ml4qf.utils.split_df_date(df_factors,
                                          split_index=config.split_data_idx)
#+end_src

#+NAME: Factors_evolution 
#+begin_src python :results value file  :exports results :var name=(org-element-property :name (org-element-context))
  # Plot monthly Factors evolution 
  fig1_path= img_dir / f'{name}.png'
  fig1 = px.line(df_factors, y=factor_names)
  fig1.write_image(fig1_path)
  fig1_path # 
#+end_src
#+CAPTION: Factors evolution
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: Factors_evolution
[[file:img/Factors_evolution.png]]

#+NAME: RFrate_evolution
#+begin_src python :results value file  :exports results :var name=(org-element-property  :name (org-element-context)) 
  fig1_path= img_dir / f'{name}.png'
  fig1 = px.line(df_factors*12, y='RF')
  fig1.write_image(fig1_path)
  fig1_path #
#+end_src
#+CAPTION: (Annualised) risk-free rate evolution
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: RFrate_evolution
[[file:img/RFrate_evolution.png]]

*** Factor regression
#+NAME: Compute regression on assets returns vs factors
#+begin_src python :results none
  # Compute regression on assets returns vs factors
  factor_models = financial_factors.factors_regression(factor_names,
                                                       df_factors_train,
                                                       df_assets_train,
                                                       regression_kernel=regression_OLS)
  alpha, beta = financial_factors.compute_factors_coeff(factor_models)
  factor_model = financial_factors.factor_lin_generator(alpha, beta)
#+end_src

#+NAME: Data Frame df_train_factors with alphas and betas
#+begin_src python  :results raw :exports results :tangle no
  albe = np.vstack([alpha, beta]).T
  df_index = asset_names
  df_columns = ['alpha'] + factor_names
  df_train_factors = pd.DataFrame(albe, columns=df_columns, index=df_index)
  tabulate(df_train_factors, headers=df_columns, showindex=True, tablefmt='orgtbl')
#+end_src
#+ATTR_LATEX: :width 0.7\textwidth :environment longtable :caption
#+RESULTS: Data Frame df_train_factors with alphas and betas
|      |        alpha |   Mkt-RF |       SMB |       HML |      RMW |        CMA |        MOM |
|------+--------------+----------+-----------+-----------+----------+------------+------------|
| JPM  |   0.00647651 | 0.922232 |  -0.28544 |   1.18559 | -1.07209 |  -0.493312 |  -0.273228 |
| CVS  |  -0.00148262 | 0.868157 | -0.215823 |  0.012167 |  0.25336 |    1.07393 |   0.026691 |
| ATVI |    0.0197562 | 0.889834 |  0.242885 | -0.206069 | -0.47066 |   0.212356 |    0.39213 |
| PH   |  -0.00382804 |  1.49288 |  0.446137 | -0.124334 |  1.14579 |   0.475606 |  -0.236351 |
| WELL |  0.000788633 |  0.58505 |  0.356454 |  0.135987 | 0.250443 |   0.247888 | -0.0239137 |
| YUM  |   0.00341028 | 0.876246 |  0.410095 | -0.205616 |  1.00998 |  0.0557652 |  -0.120782 |
| KR   | -7.80218e-05 | 0.758796 | -0.304005 | -0.211342 | 0.349079 |   0.986875 |   0.149481 |
| ATO  |   0.00152634 | 0.401037 |  0.208798 |  -0.14717 | 0.374291 |   0.563191 |  0.0033396 |
| EQT  |  -0.00322677 |  1.09022 |  0.140145 | -0.317918 | 0.955749 |   0.672032 | -0.0193002 |
| DXC  |  -0.00517583 |  1.47021 | -0.098542 | 0.0172014 | 0.263557 | 0.00627073 |  -0.250473 |

#+NAME: Summary of factors OLS
#+begin_src python :results output :exports results :tangle no
  print(factor_models[asset_names[3]].summary())
#+end_src
#+ATTR_LATEX: :width 0.7\textwidth
#+CAPTION: Summary of factors OLS
#+RESULTS: Summary of factors OLS
#+begin_example
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.607
Model:                            OLS   Adj. R-squared:                  0.597
Method:                 Least Squares   F-statistic:                     61.61
Date:                Wed, 16 Aug 2023   Prob (F-statistic):           8.36e-46
Time:                        11:21:06   Log-Likelihood:                 370.35
No. Observations:                 246   AIC:                            -726.7
Df Residuals:                     239   BIC:                            -702.2
Df Model:                           6                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         -0.0038      0.004     -1.031      0.304      -0.011       0.003
x1             1.4929      0.096     15.580      0.000       1.304       1.682
x2             0.4461      0.138      3.232      0.001       0.174       0.718
x3            -0.1243      0.155     -0.801      0.424      -0.430       0.181
x4             1.1458      0.175      6.534      0.000       0.800       1.491
x5             0.4756      0.233      2.043      0.042       0.017       0.934
x6            -0.2364      0.076     -3.108      0.002      -0.386      -0.087
==============================================================================
Omnibus:                        2.827   Durbin-Watson:                   2.164
Prob(Omnibus):                  0.243   Jarque-Bera (JB):                3.056
Skew:                          -0.008   Prob(JB):                        0.217
Kurtosis:                       3.546   Cond. No.                         75.0
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
#+end_example

#+NAME: Compute factor model prediction
#+begin_src python :results none
  # Compute factor model prediction
  # prediction on test data
  returns_pred = factor_model(df_factors_test[factor_names].to_numpy())
  df_returns_pred = pd.DataFrame(returns_pred,
                                 columns=asset_names,
                                 index=df_assets_test.index)
  # prediction on training data
  returns_predt = factor_model(df_factors_train[factor_names].to_numpy())
  df_returns_predt = pd.DataFrame(returns_predt,
                                 columns=asset_names,
                                 index=df_assets_train.index)

#+end_src

*** Factors backtesting
#+begin_comment
#+NAME: predicted_returns
#+begin_src python :var i_asset=0 name=(org-element-property :name (org-element-context))
  i_asset = i_asset
  i_name = asset_names[i_asset]
  fig1_path= img_dir / f'{name}{i_name}.png'
  fig1 = go.Figure()
  fig1.add_trace(go.Scatter(
      x=df_assets_test.index,
      y=df_assets_test.iloc[:, i_asset] - df_factors_test.RF.to_numpy(),
      mode='lines+markers',
      name=f"{i_name} real"))
  fig1.add_trace(go.Scatter(
      x=df_assets_test.index,
      y=df_returns_pred[i_name],
      mode='lines',
      name=f"{i_name} pred."))

  #px.line(df_returns_pred['GOOGL'], y=df_returns_pred.keys()[0])

  fig1.write_image(fig1_path)
  str(fig1_path)
#+end_src

#+NAME: predicted_returns0
#+begin_src python :noweb eval :results value file  :exports results 
  fig_path = "<<predicted_returns(i_asset=0, name="predicted_returns_")>>"
  fig_path
#+end_src
#+CAPTION:  Backtesting factor approximation on Google asset
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: predicted_returns0
#+end_comment

#+NAME: Function to plot returns from factor model
#+begin_src python :results none 
  def plot_rets_fromfactors(df_assets,
                            df_factors,
                            df_returns_pred,
                            i_asset,
                            name):

      i_name = asset_names[i_asset]
      fig1_path= img_dir / f'{name}{i_name}.png'
      fig1 = go.Figure()
      fig1.add_trace(go.Scatter(
          x=df_assets.index,
          y=df_assets.iloc[:, i_asset] - df_factors.RF.to_numpy(),
          mode='lines+markers',
          name=f"{i_name} real"))
      fig1.add_trace(go.Scatter(
          x=df_assets.index,
          y=df_returns_pred[i_name],
          mode='lines',
          name=f"{i_name} pred."))

      #px.line(df_returns_pred['GOOGL'], y=df_returns_pred.keys()[0])

      fig1.write_image(fig1_path)
      return str(fig1_path)

#+end_src

#+NAME: predicted_factorreturns_test
#+begin_src python :noweb eval :results value file  :exports results :var name=(org-element-property :name (org-element-context)) 
  fig1_path = plot_rets_fromfactors(df_assets_test,
                                   df_factors_test,
                                   df_returns_pred,
                                   i_asset=0, name=name)
  fig1_path #
#+end_src
#+CAPTION:  Backtesting factor approaximation on Google asset
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: predicted_factorreturns_test
[[file:img/predicted_factorreturns_testJPM.png]]

#+NAME: predicted_factorreturns_train
#+begin_src python :noweb eval :results value file  :exports results :var name=(org-element-property :name (org-element-context))
  fig1_path = plot_rets_fromfactors(df_assets_train,
                                    df_factors_train,
                                    df_returns_predt,
                                    i_asset=0, name=name)
  fig1_path #
#+end_src
#+CAPTION:  Backtesting factor approaximation on Google asset
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: predicted_factorreturns_train
[[file:img/predicted_factorreturns_trainJPM.png]]

** Generation of asset views
:PROPERTIES:
:header-args: :session py1 :tangle yes 
:END:
*** ARIMA model construction
#+BEGIN_COMMENT
#+NAME: arima_autocorrelation
#+begin_src python :results value file  :exports results :var name=(org-element-property :name  (org-element-context)) 
  fig1_path= img_dir / f'{name}.png'
  fig = plt.figure()
  ax = autocorrelation_plot(df_train_factors['SMB'])
  #ax.set_title("bleh")
  #ax.set_xlabel("xlabel")
  #ax.plot(x, y, 'r--')
  fig.savefig(fig1_path)
  fig1_path
#+end_src
#+RESULTS: arima_autocorrelation
[[file:img/arima_autocorrelation.png]]
#+END_COMMENT

#+begin_src python :results none
  def pick_arimahyper(errs):
      arima_parameters = dict()
      derrors = collections.defaultdict(list)
      derrorsind = collections.defaultdict(list)
      minvalue = collections.defaultdict(list)
      index = collections.defaultdict(list)  
      for k, v in errs.items():
          conv = k.split('_')
          derrors[conv[0]].append(v)
          derrorsind[conv[0]].append(tuple(int(i) for i in conv[1:]))
      for k, v in derrors.items():
          index[k] = v.index(min(v))
          minvalue[k] = min(v)
          arima_parameters[k] = derrorsind[k][index[k]]
      return arima_parameters, derrors, derrorsind, minvalue
#+end_src


#+begin_src python :results none
  if config.compute_arima_parameters:
      errs_train, errs_test = model_stats.arima_hyperparameters(
          df_factors_train, # 
          df_factors_test,
          factor_names,
          [0, 2, 5, 9, 13, 17, 23, 29, 35],
          [0, 1, 2, 4, 7, 9],
          [0, 2, 5, 9, 13, 17, 23, 29],
          model_stats.err_mse,
          dict(enforce_stationarity=False,
               enforce_invertibility=False)
      )
      arima_parameters, derrors, derrorsind, minvalue = pick_arimahyper(errs_test)
  else:
      arima_parameters = config.arima_parameters
#+end_src


*** COMMENT ARIMA test
#+begin_src python :results none 
  Xtrain = df_factors_train[factor_names].to_numpy()
  Xtest = df_factors_test[factor_names].to_numpy()
  index_train = df_factors_train.index
  index_test = df_factors_test.index
  arima_parameters = {'Mkt-RF': (15,0,15),
                      'SMB': (15,0,9),
                      'HML': (6,0,3),
                      'RMW': (15,0,6),
                      'CMA': (6,4,12),
                      'MOM': (0,1,0)
                      }
  #arima_parameters = config.arima_parameters
  model_sett = dict(enforce_stationarity=False,
                    enforce_invertibility=False) 
  arima_train_models = model_stats.arima_fit(Xtrain,
                                             factor_names,
                                             arima_parameters,
                                             model_sett=model_sett)
  df_arimatrain, df_arimatest = model_stats.arima_build_pred(arima_train_models,
                                                             Xtrain,
                                                             Xtest,
                                                             factor_names,
                                                             index_train,
                                                             index_test)  
#+end_src

#+begin_src python :results output  
  print(arima_train_models['Mkt-RF'].summary())
#+end_src

#+RESULTS:
#+begin_example
                               SARIMAX Results                                
==============================================================================
Dep. Variable:                      y   No. Observations:                  246
Model:                 ARIMA(0, 0, 5)   Log Likelihood                 406.466
Date:                Wed, 16 Aug 2023   AIC                           -798.932
Time:                        12:56:36   BIC                           -774.567
Sample:                             0   HQIC                          -789.115
                                - 246                                         
Covariance Type:                  opg                                         
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
const          0.0052      0.004      1.220      0.223      -0.003       0.014
ma.L1          0.1244      0.054      2.296      0.022       0.018       0.231
ma.L2         -0.0490      0.062     -0.791      0.429      -0.170       0.072
ma.L3          0.0690      0.062      1.113      0.266      -0.053       0.190
ma.L4          0.0429      0.059      0.726      0.468      -0.073       0.159
ma.L5          0.0382      0.058      0.656      0.512      -0.076       0.152
sigma2         0.0020      0.000     12.825      0.000       0.002       0.002
===================================================================================
Ljung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):                14.85
Prob(Q):                              0.96   Prob(JB):                         0.00
Heteroskedasticity (H):               1.07   Skew:                            -0.35
Prob(H) (two-sided):                  0.76   Kurtosis:                         4.00
===================================================================================

Warnings:
[1] Covariance matrix calculated using the outer product of gradients (complex-step).
#+end_example

*** COMMENT ARIMA backtesting

#+begin_src python :results none 
  # prediction on train data
  fnames_prediction = [k for k in df_arimatrain.columns if "_pred" in k]
  asset_names_pred = [k + '_pred' for k in asset_names]
  returns_arimapred_train = factor_model(df_arimatrain[fnames_prediction].to_numpy())
  df_arimapred_train = pd.DataFrame(returns_arimapred_train,
                                    columns=asset_names_pred,
                                    index=df_assets_train.index[:-1])
  df_arimaasset_train = df_arimapred_train.join(df_assets_train)
  # prediction on test data
  returns_arimapred_test = factor_model(df_arimatest[fnames_prediction].to_numpy())
  df_arimapred_test = pd.DataFrame(returns_arimapred_test,
                                   columns=asset_names_pred,
                                   index=df_assets_test.index[:-1])
  df_arimaasset_test = df_arimapred_test.join(df_assets_test)
  # # prediction on training data
  df_arimatest_profits = ml4qf.utils.profit_portfolio(
     df_arimaasset_test,
     {k: 1. for k in df_arimaasset_test.columns})
#+end_src


#+NAME: ARIMA_returnsbacktest
#+begin_src python :results value file :exports results :var name=(org-element-property :name  (org-element-context)) 
  fig1_path= img_dir / f'{name}.png'
  fig1 = px.line(df_arimaasset_test, y=['JPM_pred', 'JPM','EQT','EQT_pred'])
  fig1.write_image(fig1_path)
  fig1_path #

#+end_src
#+CAPTION: daa
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: ARIMA_returnsbacktest
[[file:img/ARIMA_returnsbacktest.png]]


#+NAME: ARIMA_backtest
#+begin_src python :results value file :exports results :var name=(org-element-property :name  (org-element-context)) 
  fig1_path= img_dir / f'{name}.png'
  fig1 = px.line(df_arimatest_profits, y=['ATO', 'ATO_pred', 'KR','KR_pred'])
  fig1.write_image(fig1_path)
  fig1_path #

#+end_src
#+CAPTION: daa
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: ARIMA_backtest
[[file:img/ARIMA_backtest.png]]

*** COMMENT ARIMA model prediction

#+NAME: ARIMA_Mkt-RF_train
#+begin_src python :results value file :exports results :var name=(org-element-property :name (org-element-context)) 
  fig1_path= img_dir / f'{name}.png'
  fig1 = px.line(df_arimatrain, y=['MOM','MOM_pred'])
  fig1.write_image(fig1_path)
  fig1_path #

#+end_src
#+CAPTION: d
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: ARIMA_Mkt-RF_train
[[file:img/ARIMA_Mkt-RF_train.png]]

#+NAME: ARIMA_Mkt-RF_test
#+begin_src python :results value file :exports results :var name=(org-element-property :name  (org-element-context)) 
  fig1_path= img_dir / f'{name}.png'
  fig1 = px.line(df_arimatest, y=['MOM','MOM_pred'])
  fig1.write_image(fig1_path)
  fig1_path #

#+end_src
#+CAPTION: d
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: ARIMA_Mkt-RF_test
[[file:img/ARIMA_Mkt-RF_test.png]]

** COMMENT Black-Litterman based portfolio
:PROPERTIES:
:header-args: :session py1 :tangle no
:END:

*** Views
EQT will rise 15%
PH to outperform JPM by 11%
KR to outperform ATO by 8%

*** Covariance treatment
*** Prior and posterior returns construction

#+NAME: Calculate Covariance of excess returns
#+begin_src python :results none 
  df_Sigma_factors = df_factors[factor_names].cov()
  df_Sigma_factors_train = df_factors_train[factor_names].cov()
  df_Sigma_factors_test = df_factors_test[factor_names].cov()
  Sigma_factors = df_Sigma_factors.to_numpy()
  Sigmainv_factors = np.linalg.inv(Sigma_factors)
  Sigma_factors_train = df_Sigma_factors_train.to_numpy()
  Sigmainv_factors_train = np.linalg.inv(Sigma_factors_train)
  Sigma_factors_test = df_Sigma_factors_test.to_numpy()
  Sigmainv_factors_test = np.linalg.inv(Sigma_factors_test)
  #####
  df_Sigma_assets = df_assets.cov()
  df_Sigma_assets_train = df_assets_train.cov()
  df_Sigma_assets_test = df_assets_test.cov()
  Sigma_assets = df_Sigma_assets.to_numpy()
  Sigmainv_assets = np.linalg.inv(Sigma_assets)
  Sigma_assets_train = df_Sigma_assets_train.to_numpy()
  Sigmainv_assets_train = np.linalg.inv(Sigma_assets_train)
  Sigma_assets_test = df_Sigma_assets_test.to_numpy()
  Sigmainv_assets_test = np.linalg.inv(Sigma_assets_test)
  #####
  Sigma_4mfactors = beta.T @ Sigma_factors @ beta
  Sigmainv_4mfactors = np.linalg.inv(Sigma_4mfactors)
  Sigma_4mfactors_train = beta.T @ Sigma_factors_train @ beta
  Sigmainv_4mfactors_train = np.linalg.inv(Sigma_4mfactors_train)
  Sigma_4mfactors_test = beta.T @ Sigma_factors_test @ beta
  Sigmainv_4mfactors_test = np.linalg.inv(Sigma_4mfactors_test)

#+end_src

#+NAME: Compute equilibrium returns 
#+begin_src python :results none 
  f_mu = lambda l, S, w: l * S @ w
  mu_mkt_assets = f_mu(config.lambda_mkt, Sigma_assets_train, w_mkt)
  mu_mkt_4mfactors = f_mu(config.lambda_mkt, Sigma_4mfactors_train, w_mkt)
  w1_assets_theoretical = optimization.mean_variance_opt(mu_mkt_assets, Sigmainv_assets_train, config.lambda_portfolio[0])
  w2_assets_theoretical = optimization.mean_variance_opt(mu_mkt_assets, Sigmainv_assets_train, config.lambda_portfolio[1])
  w3_assets_theoretical = optimization.mean_variance_opt(mu_mkt_assets, Sigmainv_assets_train, config.lambda_portfolio[2])
  w1_4mfactors_theoretical = optimization.mean_variance_opt(mu_mkt_4mfactors, Sigmainv_4mfactors_train, config.lambda_portfolio[0])
  w2_4mfactors_theoretical = optimization.mean_variance_opt(mu_mkt_4mfactors, Sigmainv_4mfactors_train, config.lambda_portfolio[1])
  w3_4mfactors_theoretical = optimization.mean_variance_opt(mu_mkt_4mfactors, Sigmainv_4mfactors_train, config.lambda_portfolio[2])
#+end_src

#+NAME: Black-Litterman initialisation
#+begin_src python :results none 
  bl_model_Sassets = bl.BlackLitterman(Sigma_assets_train, w_mkt, config.lambda_mkt)
  bl_model_Sassets.set_portfolio_inputs(config.tau, config.P, config.Q)
  bl_model_Sfactors = bl.BlackLitterman(Sigma_4mfactors_train, w_mkt, config.lambda_mkt)
  bl_model_Sfactors.set_portfolio_inputs(config.tau, config.P, config.Q)

  bl_model_Sfactors.mu_mkt
  bl_model_Sassets.mu_mkt
#+end_src

*** Portfolio weights optimisation

#+NAME: Calculate Covariance of factors
#+begin_src python :results none 

  lmb_p = config.lambda_portfolio[2]
  x0 = 1. / num_assets * np.ones(num_assets)
  args = (bl_model_Sassets.mu_bl,            
          bl_model_Sassets.Sigma,          
          lmb_p)
  res = optimization.scipy_minimize("mean_variance",
                                    x0,
                                    method_name='SLSQP',
                                    args=args,
                                    options=dict(maxiter=200,
                                                 ftol=1e-12))
  w1_assets_opt = res.x
#+end_src

#+NAME: Compute porfolio weights frontier
#+begin_src python :results none 

  lmb_p = config.lambda_portfolio[2]

  x0 = 1. / num_assets * np.ones(num_assets)
  args = (mu_mkt_assets*12,
          Sigma_assets,
          0.1)
  args = (bl_model_Sassets.mu_mkt*12,            
          bl_model_Sassets.Sigma,          
          0.06)

  cons_sett = dict(eq_rets=dict(type="eq"),
                   eq_weights1=dict(type="eq"),
                   ieq_weights0=dict(type="ineq")
                   )
  res1 = optimization.scipy_minimize("variance",
                                     x0,
                                     method_name='SLSQP',
                                     args=args,
                                     cons_sett=cons_sett,
                                     options=dict(maxiter=200,
                                                  ftol=1e-12))

  print(np.dot(res1.x, Sigma_assets @ res1.x)**0.5 * 12**0.5 * 100)
  print(res1.fun**0.5 * 12**0.5 * 100)
  print(sum(res1.x))
  print(res1.x)
#+end_src

#+NAME: Function to build portfolios weights
#+begin_src python :results none 

  def build_portfolio_weights(mu_targetlist,
                              x0,
                              mu_portfolio,
                              Sigma_portfolio,
                              cons_sett,
                              annualise=12):

      res_list = list()
      for mu_i in mu_targetlist:
          args = (mu_portfolio * annualise, # annualised
                  Sigma_portfolio,
                  mu_i)
          res = optimization.scipy_minimize("variance",
                                             x0,
                                             method_name='SLSQP',
                                             args=args,
                                             cons_sett=cons_sett,
                                             options=dict(maxiter=200,
                                                          ftol=1e-12))
          res_list.append(res)
      return res_list

#+end_src

#+NAME: Function to compute weights vs volatility for target returns
#+begin_src python :results none 

  def build_df_weightsvol(assets,
                          mu_targetlist,
                          x0,
                          lmb_p,
                          mu_portfolio,
                          Sigma_portfolio,
                          annualise=12):

      # constraints: returns equal to a number given in mu_targetlist,
      # weights equal to 1, and all weights greater than 0
      cons_sett = dict(eq_rets=dict(type="eq"),
                       eq_weights1=dict(type="eq"),
                       ieq_weights0=dict(type="ineq")
                       )

      res_list = build_portfolio_weights(mu_targetlist,
                                         x0,
                                         mu_portfolio,
                                         Sigma_portfolio,
                                         cons_sett,
                                         annualise
                                         )


      weights = np.array([ri.x for ri in res_list])
      Weights = weights.flatten()
      # anualise vols
      vols=[((ri.fun) * annualise)**0.5 for ri in res_list]
      Vols = [vi for vi in vols for i in range(len(assets))]
      Assets = [k for i in range(len(vols)) for k in assets]
      df_weights_vols = pd.DataFrame(dict(weights=Weights,
                                          vols=Vols,
                                          assets=Assets
                                          ))
      return df_weights_vols
#+end_src

#+NAME: df with portfolios weights
#+begin_src python :results none 

  lmb_p = config.lambda_portfolio[2]
  x0 = 1. / num_assets * np.ones(num_assets)
  mu_targetlist = np.linspace(4,18,16) * 1e-2
  df_weights_vols = build_df_weightsvol(asset_names, mu_targetlist, x0, lmb_p,
                                        mu_mkt_assets,
                                        Sigma_assets)

#+end_src

#+NAME: Weights_Composition
#+begin_src python :results value file  :exports results :var name=(org-element-property :name  (org-element-context)) 
  fig1_path= img_dir / f'{name}.png'
  fig1 = px.area(df_weights_vols, x="vols", y="weights", color="assets",
                #pattern_shape_sequence=[".", "x", "+"],              
                pattern_shape="assets"
                )
  fig1.write_image(fig1_path)
  fig1_path
#+end_src

#+RESULTS: Weights_Composition
[[file:img/Weights_Composition.png]]


#+begin_src python :results none 
  weights_sol = {k: res1.x[i] for i, k in enumerate(asset_names)}
  df_profits_sol = ml4qf.utils.profit_portfolio(df_assets_test, weights_sol)
  weights_naive = {k: x0[i] for i, k in enumerate(asset_names)}  
  df_profits_naive = ml4qf.utils.profit_portfolio(df_assets_test, weights_naive)

  df_profits = pd.DataFrame(np.array([df_profits_sol.sum(axis=1).to_numpy(),
                             df_profits_naive.sum(axis=1).to_numpy()]).T,
                             columns=['Opt', 'Naive'], index=df_profits_sol.index)
#+end_src

#+NAME: P&L_plot
#+begin_src python :results value file  :exports results :var name=(org-element-property :name  (org-element-context)) 
  fig1_path= img_dir / f'{name}.png'
  fig1 = px.line(df_profits, y=['Opt', 'Naive'], markers=True)
  fig1.write_image(fig1_path)
  fig1_path
#+end_src

#+RESULTS: P&L_plot
[[file:img/P&L_plot.png]]

*** Analysis and discussion

- active risk (Table 6)
*** Performance comparison



#+LaTeX: \appendix
* Code execution
The codes herein have been tested in linux (Ubuntu 22 and Centos 8) and in MacOs


** Testing
