#+TITLE: Portfolio Construction using Black-Litterman Model and Factors
#+AUTHOR: Alvaro Cea
#+PROPERTY: header-args :tangle ./main.py :mkdirp yes
#+LATEX_HEADER: \usepackage[margin=1in]{geometry}
#+LATEX_HEADER: \usepackage{mathtools}

#+begin_comment
#+OPTIONS: toc:nil
#+LATEX_HEADER: \let\oldsection\section
#+LATEX_HEADER: \renewcommand{\section}{\clearpage\oldsection}
#+LATEX_HEADER: \let\oldsubsection\subsection
#+LATEX_HEADER: \renewcommand{\subsection}{\clearpage\oldsubsection}
#+end_comment

* House keeping :noexport:
#+begin_src elisp :results none :exports none
  (add-to-list 'org-structure-template-alist
  '("sp" . "src python :session py1"))
  (add-to-list 'org-structure-template-alist
  '("se" . "src elisp"))

  (setq org-confirm-babel-evaluate nil)
  (pyvenv-workon "ml4qf")
  (require 'org-tempo)
  (setq org-format-latex-options (plist-put org-format-latex-options :scale 2.0))
  (setq org-latex-pdf-process (list "latexmk -f -synctex=1 -pdf %f"))
  ;; (setq org-latex-pdf-process (list "latexmk -f -pdf -interaction=nonstopmode -output-directory=%o %f"))

#+end_src

#+begin_src python :session py1 :tangle yes :results none :exports none
  import pandas as pd
  import numpy as np
  import yfinance as yf
  import statsmodels.api as sm
  import getFamaFrenchFactors as gff
  import pathlib
  import datetime
  import importlib
  import ml4qf
  import ml4qf.collectors.financial_features as financial_features
  import ml4qf.collectors.financial_factors as financial_factors
  import ml4qf.collectors.financial_markets as financial_markets
  from ml4qf.predictors.model_stats import regression_OLS
  import plotly.express as px
  import config
  importlib.reload(config)
  img_dir = "./img/"
  pathlib.Path(img_dir).mkdir(parents=True, exist_ok=True)
#+end_src

* Introduction
** Develop computational tools and external libraries
- getFamaFrenchFactors
  gets data for fame french factors from the Kenneth French library
  https://pypi.org/project/getFamaFrenchFactors/
** Specifications:
For risk-free rate, 3M US Treasury from pandas FRED dataset/ECB website
rates for EUR/some small constant rate/zero rate – all are acceptable.
Use 2-3 year sample, which means > 500 daily returns.
** Index selection
The S&P 500 is considered a better reflection of the market’s performance across all sectors compared to the Nasdaq Composite and the Dow

#+begin_comment
#+CAPTION: Modal shape 1 
#+ATTR_LATEX: :width 0.75\textwidth
#+ATTR_ORG: :width 100
[[./img/polimi-M0.png]]
#+end_comment

* Theory
** Fama-French factors

It is one of the multi-factor models which is widely used in both academia and industry to estimate the excess return of an investment asset. It is an extension to Capital Asset Pricing Model (CAPM) by adding two additional factors apart from the market risk when estimating the excess returns of an asset. The three factors considered in this model are:

    Market factor (MKT) — Excess market return
    Size factor (SMB) — Excess return with a small market cap over those with a large market cap
    Value factor (HML) — Excess return of value stocks over growth stocks.

The Fama-French model is widely known as a stock market benchmark to evaluate investment performance.

** Black-Litterman model

$$
\mu_{eq} = \lambda \Sigma w_{mkt}
$$

- $\mu_{eq}$ is the Implied Excess Equilibrium Return Vector 
- $\lambda$ is the risk aversion coefficient, $\lambda = \frac{E(\mu) - \mu_r}{\sigma^2}$
- $\Sigma$ is the covariance matrix of excess returns
- $w_{mkt}$ are market capitalization weights

$$
E[\mu_{bl}] = \left[(\tau \Sigma)^{-1} + P'\Omega^{-1}P\right]^{-1} \left[(\tau \Sigma)^{-1}\mu_{eq} + P'\Omega^{-1}Q\right]  
$$

- $E[\mu_{bl}]$: Posterior combined return vector ($N\times a$)
- $\tau$: error in views
- $P$: Matrix identifying assets involved in the views ($K\times N$)
- $Q$: View vector ($K\times 1$)
- $\Omega$: Diagonal covariance matrix with the errors expressed in the views ($N\times N$). 

Normal distributions:

- Prior equilibrium distribution: $N(\mu_{eq}, \tau \Sigma)$
- Views distribution: $N(Q, \Omega)$
- New combined return distribution: $N\left(E[\mu_{bl}], \left[(\tau \Sigma)^{-1} + P'\Omega^{-1}P\right]^{-1} \right)$
** Optimisation

- Minimise Mean variance
- Maximize Sharpe ratio
- Hierarchical Risk Parity (HRP)   

* Results
** Portfolio and Factor analysis
:PROPERTIES:
:header-args: :session py1 :tangle yes
:END:

*** Asset selection
#+begin_src python  :results none
  tickers_sp500 = ml4qf.collectors.scrap_tickers_index(config.index_weblist)
  df_tickers_sp500 = ml4qf.collectors.get_tickers_info(tickers_sp500,
                                                   config.info_sp500,
                                                   data_folder="./data",
                                                   name_family="sp500")
  df_tickers_sp500.dropna(inplace=True)
  df_tickers_filtered = ml4qf.utils.date_filter_lower(df_tickers_sp500,
                                                'first_date',
                                                date_lower=config.start_date_assets)
  df_tickers_filtered =  df_tickers_filtered.sort_values('marketCap',ascending=False)
  df_selected_tickers = ml4qf.collectors.select_assets(df_tickers_filtered,
                                                       config.ASSET_SELECTION_PCT,
                                                       config.ASSET_SELECTION_NAMES)
  # #FinancialDataContainer
  w_mkt = df_selected_tickers.marketCap / df_selected_tickers.marketCap.sum()
#+end_src

- Market cap equilibrium weights
#+begin_src python :tangle yes :results output
  portfolios_path = pathlib.Path("./data/portfolios/")
  portfolios_path.mkdir(parents=True, exist_ok=True)
  portfolios_file = portfolios_path / ("_".join(df_selected_tickers.index))
  if not portfolios_file.is_file():
      df_selected_tickers.to_csv(portfolios_file)
  print(w_mkt)
  #w_mkt = w_mkt.to_numpy()
#+end_src

#+RESULTS:
#+begin_example
UNH     0.522293
MCD     0.233716
ETN     0.096325
COF     0.046844
IT      0.029819
SBAC    0.027697
CNP     0.020226
TAP     0.015441
CMA     0.007640
Name: marketCap, dtype: float64
#+end_example

*** Assets exploratory analysis
#+begin_src python  :results none
  fdc = financial_features.FinancialDataContainer(df_selected_tickers.index,
                                                  config.start_date_assets,
                                                  config.end_date_assets,
                                                  '1mo',
                                                  './data')
  df_assets = fdc.df.dropna()
  df_assets_train, df_assets_test = ml4qf.utils.split_df_date(df_assets,
                                                   split_index=config.split_data_idx)
#+end_src

#+NAME: df_assets
#+begin_src python :session py1 :results raw :exports results
  tabulate(df_assets.iloc[:10], headers=df_assets.columns,showindex=True, tablefmt='orgtbl')
#+end_src

#+ATTR_LATEX: :width 0.7\textwidth :environment longtable :caption  
#+RESULTS: df_assets
|                     |         UNH |         MCD |        ETN |        COF |         IT |        SBAC |        CNP |         TAP |         CMA |
|---------------------+-------------+-------------+------------+------------+------------+-------------+------------+-------------+-------------|
| 2016-08-01 00:00:00 |  -0.0499301 |  -0.0169146 |  0.0493613 |  0.0673822 | -0.0922693 | -0.00739129 | -0.0606188 |  0.00156613 |   0.0453139 |
| 2016-09-01 00:00:00 |   0.0290334 | -0.00259384 | -0.0124737 | 0.00321234 |  -0.028022 |  -0.0174332 |  0.0338229 |    0.073104 | 0.000634358 |
| 2016-10-01 00:00:00 |  0.00950001 |  -0.0241852 | -0.0295236 |  0.0307671 |  -0.027247 |  0.00998569 | -0.0185106 |  -0.0545538 |    0.100803 |
| 2016-11-01 00:00:00 |    0.120215 |   0.0595185 |  0.0429669 |   0.135062 |   0.195026 |   -0.126412 |  0.0464913 |  -0.0556786 |    0.223843 |
| 2016-12-01 00:00:00 |    0.010864 |   0.0205417 | 0.00872041 |  0.0380771 |   -0.01702 |   0.0434519 |  0.0326906 |  -0.0073447 |   0.0683922 |
| 2017-01-01 00:00:00 |   0.0128719 |  0.00698323 |  0.0550008 | 0.00171941 |  -0.016919 |   0.0193686 |  0.0637175 | -0.00811839 | -0.00851566 |
| 2017-02-01 00:00:00 |   0.0202344 |   0.0414457 |   0.016954 |  0.0740359 |   0.038748 |   0.0998479 |  0.0423503 |   0.0400953 |   0.0555309 |
| 2017-03-01 00:00:00 | -0.00828401 |   0.0153545 |  0.0301472 |   -0.07671 |  0.0463133 |    0.039734 | 0.00915081 |  -0.0466182 |  -0.0378787 |
| 2017-04-01 00:00:00 |   0.0662765 |   0.0796234 |  0.0200944 | -0.0724672 |  0.0564867 |   0.0508432 |  0.0348205 |  0.00188068 |   0.0309127 |
| 2017-05-01 00:00:00 |  0.00171539 |   0.0783249 |  0.0230037 | -0.0430455 |  0.0482952 |   0.0924183 | 0.00280406 |  -0.0114715 |  -0.0302687 |



#+NAME: basket_returns
#+begin_src python :results value file  :exports results :var name=(org-element-property :name (org-element-context))
  fig1_path= img_dir + f'{name}.png'
  fig1 = px.line(df_assets, y=df_assets.keys())
  fig1.write_image(fig1_path)
  fig1_path
#+end_src

#+CAPTION:  Asset's basket returns
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: basket_returns
[[file:./img/basket_returns.png]]



#+NAME: AssetsCorrelation
#+begin_src python :results value file  :exports results :var name=(org-element-property :name (org-element-context))
  fig1_path= img_dir + f'{name}.png'
  df_corr = df_assets.corr().round(2)
  fig1 = px.imshow(np.abs(df_corr))
  fig1.layout.height = 600
  fig1.layout.width = 600
  fig1.write_image(fig1_path)
  fig1_path
#+end_src

#+CAPTION: Assets correlation
#+ATTR_LATEX: :width 0.75\textwidth 
#+RESULTS: AssetsCorrelation
[[file:./img//AssetsCorrelation.png]]



*** Factor collection
#+begin_src python :tangle yes :results none
  factor_names = financial_factors.get_factor_names(config.FACTORS)  
  df_factors0 = financial_factors.get_factors(config.FACTORS.keys(), 'm')
  df_factors =  ml4qf.utils.trim_df_date(df_factors0, start_date=config.start_date_factors,
                                         end_date=config.end_date_factors)
  df_factors_train, df_factors_test = ml4qf.utils.split_df_date(df_factors,
                                          split_index=config.split_data_idx)
#+end_src

*** Factor regression
#+begin_src python :tangle yes :results none
  factor_models = financial_factors.factors_regression(factor_names,
                                                      df_factors_train,
                                                      df_assets_train,
                                                      regression_kernel=regression_OLS)
  alpha, beta = financial_factors.compute_factors_coeff(factor_models)
  factor_model = financial_factors.factor_lin_generator(alpha, beta)
#+end_src

#+begin_src python :results output :exports results
  print(factor_models[df_assets.keys()[0]].summary())
#+end_src

#+RESULTS:
#+begin_example
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.520
Model:                            OLS   Adj. R-squared:                  0.450
Method:                 Least Squares   F-statistic:                     7.412
Date:                Thu, 10 Aug 2023   Prob (F-statistic):           2.06e-05
Time:                        17:18:03   Log-Likelihood:                 90.027
No. Observations:                  48   AIC:                            -166.1
Df Residuals:                      41   BIC:                            -153.0
Df Model:                           6                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         -0.0047      0.006     -0.742      0.462      -0.018       0.008
x1             0.8822      0.170      5.180      0.000       0.538       1.226
x2            -0.7053      0.300     -2.354      0.023      -1.310      -0.100
x3            -0.1531      0.246     -0.623      0.537      -0.649       0.343
x4            -0.8772      0.537     -1.634      0.110      -1.962       0.207
x5            -0.2057      0.444     -0.463      0.646      -1.103       0.692
x6            -0.4871      0.226     -2.159      0.037      -0.943      -0.032
==============================================================================
Omnibus:                        1.327   Durbin-Watson:                   2.343
Prob(Omnibus):                  0.515   Jarque-Bera (JB):                1.196
Skew:                           0.372   Prob(JB):                        0.550
Kurtosis:                       2.787   Cond. No.                         98.9
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
#+end_example


#+begin_src python :session py1 :results none :exports none
  import getFamaFrenchFactors as gff
  import yfinance as yf
  import statsmodels.api as sm

  ticker = 'amzn'
  start = '2016-8-31'
  end = '2021-8-31'
  start = '2014-12-31'
  end = '2019-12-31'
  stock_data = yf.download(ticker, start, end)

  ff3_monthly = gff.famaFrench3Factor(frequency='m')
  #ff3_monthly = gff.famaFrench5Factor(frequency='m')
  #momentum_monthly = gff.momentumFactor(frequency='m')

  ff3_monthly.rename(columns={"date_ff_factors": 'Date'}, inplace=True)
  ff3_monthly.set_index('Date', inplace=True)

  stock_returns = stock_data['Close'].resample('M').last().pct_change().dropna()
  stock_returns.name = "Month_Rtn"
  ff_data = ff3_monthly.merge(stock_returns,on='Date')

  X = ff_data[['Mkt-RF', 'SMB', 'HML']]
  y = ff_data['Month_Rtn'] - ff_data['RF']
  X = sm.add_constant(X)
  ff_model = sm.OLS(y, X).fit()
#+end_src
#+begin_src python :session py1 :results output :exports results
  print(ff_model.summary())
#+end_src

#+RESULTS:
#+begin_example
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      y   R-squared:                       0.514
Model:                            OLS   Adj. R-squared:                  0.488
Method:                 Least Squares   F-statistic:                     19.73
Date:                Thu, 10 Aug 2023   Prob (F-statistic):           7.48e-09
Time:                        15:40:50   Log-Likelihood:                 86.579
No. Observations:                  60   AIC:                            -165.2
Df Residuals:                      56   BIC:                            -156.8
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
const          0.0147      0.008      1.843      0.071      -0.001       0.031
Mkt-RF         1.5402      0.224      6.886      0.000       1.092       1.988
SMB           -0.6471      0.338     -1.914      0.061      -1.324       0.030
HML           -0.9529      0.297     -3.205      0.002      -1.549      -0.357
==============================================================================
Omnibus:                        2.723   Durbin-Watson:                   1.576
Prob(Omnibus):                  0.256   Jarque-Bera (JB):                2.361
Skew:                           0.485   Prob(JB):                        0.307
Kurtosis:                       2.949   Cond. No.                         46.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
#+end_example


#+begin_src python :tangle yes :results none
  predicted_return = factor_model(df_factors_test[factor_names].to_numpy())
#+end_src




*** P&L and backtesting
#+begin_src python :session py1 :results file
  img_dir = "./img/" + data.label
  pathlib.Path(img_dir).mkdir(parents=True, exist_ok=True)
  fig1_path= img_dir +'/stock_Close.png'
  fig1 = px.line(df_, y=['Ret_1d', 'Ret_5d', 'Ret_15d'])
  fig1.write_image(fig1_path)
  fig1_path

#+end_src


** Black-Litterman implementation
*** Prior and posterior returns construction
*** Views on
*** Covariance treatment
*** Portfolio weights optimisation
*** Analysis and discussion
*** Performance comparison
sss


#+LaTeX: \appendix
* Code execution
The codes herein have been tested in linux (Ubuntu 22 and Centos 8) and in MacOs


** Testing
