#+PROPERTY: header-args :tangle ./airbus.py :mkdirp yes
* House keeping
#+begin_src elisp :results none :tangle no
(add-to-list 'org-structure-template-alist
'("sp" . "src python :session py1"))
(add-to-list 'org-structure-template-alist
'("se" . "src elisp"))

(setq org-confirm-babel-evaluate nil)
#+end_src

#+begin_src emacs-lisp  :session py1 :results none :tangle no
(pyvenv-workon "qfpy")
(require 'org-tempo)
#+end_src

#+begin_src python  :session py1 :results none
  import sys
  import pathlib
  file_path = sys.path[1]
  sys.path.append(file_path + "/../")
#+end_src

* Import libraries
#+BEGIN_SRC python :session py1 :results output silent

  import numpy as np
  import pathlib
  import yfinance as yf
  import ml4qf
  import ml4qf.utils
  # from umap import UMAP
  # import matplotlib.pyplot as plt
  # from mpl_toolkits.mplot3d import Axes3D
  # import matplotlib
  # matplotlib.rcParams['figure.dpi'] = 80

  import minisom
  import umap
  from sklearn.model_selection import train_test_split
  import sklearn.metrics
  import scipy.optimize
  import sklearn.compose
  import sklearn.pipeline

  import plotly.express as px
  import scipy.stats
  import pandas as pd
  import pandas_ta as ta
  import ml4qf.inputs
  import ml4qf.collectors.financial_features
  import ml4qf.transformers
  import ml4qf.predictors.model_som
  import ml4qf.predictors.model_keras as model_keras
#+END_SRC

* Introduction
#+begin_src python :session py1 :results none 
df2 = yf.download("EADSY", start="2014-10-02", end="2019-10-1", interval='1d')
#df.index
#+end_src

* Feature engineering

#+begin_src python :session py1 :results none 
  FEATURES1 = {'momentum_': [1, 2, 5, 8, 15, 23],
               'OC_': None,
               'HL_': None,
               'Ret_': [1, 5, 30, 35],
               #'RetLog_': list(range(10, 90, 10)),
               'Std_': list(range(10, 90, 10)),
               'MA_': [5, 10, 25, 50],
               'EMA_': [5, 10, 25, 50],
               'sign_return_': list(range(1,10)),
               'volume_':None,
               "ema": {"close": "volume", "length": [5, 10, 20], "prefix": "VOLUME"},
               "log_return": {"length": [1, 20], "cumulative": True},
               "ohlc4":{},
               "volatility":"whole"
               #"momentum":"whole"
               #"percent_return": dict(length=2, append=False),
               #"log_return": [1, 2]
               }

  data = ml4qf.collectors.financial_features.FinancialData("EADSY", 2019, 10, 1, 365*5, FEATURES1)
  img_dir = "./img/" + data.label
  pathlib.Path(img_dir).mkdir(parents=True, exist_ok=True)
  df_  = data.features.df.drop(data.df.columns, axis=1)
  df_.dropna(inplace=True)

#+end_src


#+begin_src python :session py1 :results output
  own_features = list(df_.columns[:df_.columns.get_loc('volume_')+1])
  pa_features = list(df_.columns[df_.columns.get_loc('volume_') + 1:df_.columns.get_loc('OHLC4')+1])
  pa_volfeatures = list(df_.columns[df_.columns.get_loc('OHLC4')+1:])
  total_features = len(own_features) + len(pa_features) + len(pa_volfeatures)
  print("######################")
  print(own_features)
  print("######################")
  print(pa_features)
  print("######################")
  print(pa_volfeatures)
  print("######################")
  assert total_features == len(df_.columns), "Number of features not matching in dataframe"
#+end_src

#+RESULTS:
: ######################
: ['momentum_1d', 'momentum_2d', 'momentum_5d', 'momentum_8d', 'momentum_15d', 'momentum_23d', 'OC_', 'HL_', 'Ret_1d', 'Ret_5d', 'Ret_30d', 'Ret_35d', 'Std_10d', 'Std_20d', 'Std_30d', 'Std_40d', 'Std_50d', 'Std_60d', 'Std_70d', 'Std_80d', 'MA_5d', 'MA_10d', 'MA_25d', 'MA_50d', 'EMA_5d', 'EMA_10d', 'EMA_25d', 'EMA_50d', 'sign_return_1d', 'sign_return_2d', 'sign_return_3d', 'sign_return_4d', 'sign_return_5d', 'sign_return_6d', 'sign_return_7d', 'sign_return_8d', 'sign_return_9d', 'volume_']
: ######################
: ['VOLUME_EMA_5', 'VOLUME_EMA_10', 'VOLUME_EMA_20', 'CUMLOGRET_1', 'CUMLOGRET_20', 'OHLC4']
: ######################
: ['ABER_ZG_5_15', 'ABER_SG_5_15', 'ABER_XG_5_15', 'ABER_ATR_5_15', 'ACCBL_20', 'ACCBM_20', 'ACCBU_20', 'ATRr_14', 'BBL_5_2.0', 'BBM_5_2.0', 'BBU_5_2.0', 'BBB_5_2.0', 'BBP_5_2.0', 'DCL_20_20', 'DCM_20_20', 'DCU_20_20', 'HWM', 'HWU', 'HWL', 'KCLe_20_2', 'KCBe_20_2', 'KCUe_20_2', 'MASSI_9_25', 'NATR_14', 'PDIST', 'RVI_14', 'THERMO_20_2_0.5', 'THERMOma_20_2_0.5', 'THERMOl_20_2_0.5', 'THERMOs_20_2_0.5', 'TRUERANGE_1', 'UI_14']
: ######################

** Exploratory data analysis


#+begin_src python :session py1 :results file
  fig1_path= img_dir +'/stock_Close.png'
  fig1 = px.line(df_, y=['momentum_1d', 'momentum_5d', 'momentum_15d'])
  fig1.write_image(fig1_path)
  fig1_path
#+end_src

#+RESULTS:
[[file:./img/_EADSY_2014-10-02_2019-10-01/stock_Close.png]]

*** Correlation

#+begin_src python :session py1 :results file
  fig1_path= img_dir +'/correlation.png'
  df_corr = df_.corr().round(2)
  fig1 = px.imshow(np.abs(df_corr))
  fig1.layout.height = 600
  fig1.layout.width = 600
  fig1.write_image(fig1_path)
  fig1_path
#+end_src

#+RESULTS:
[[file:./img/_EADSY_2014-10-02_2019-10-01/correlation.png]]

** Label 

*** Class imbalance

#+begin_src python :session py1
ymin = scipy.optimize.bisect(ml4qf.utils.fix_imbalance, -0.01, 0.01, args=(data, df_.index))
df_['target'] = np.where(data.df.loc[df_.index]['returns'].shift(-1) > ymin, 1, 0)
df_.target.value_counts()
#+end_src

#+RESULTS:
: 0    589
: 1    588
: Name: target, dtype: int64

** Feature scaling

https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02


#+begin_src python :session py1 :results output 
zscores = np.abs(scipy.stats.zscore(df_)).max()
print(zscores)
#+end_src

#+RESULTS:
#+begin_example
momentum_1d         7.405875
momentum_2d         6.255884
momentum_5d         5.205477
momentum_8d         4.774641
momentum_15d        3.323660
                      ...   
THERMOl_20_2_0.5    3.212057
THERMOs_20_2_0.5    1.721326
TRUERANGE_1         9.057901
UI_14               3.888160
target              1.000850
Length: 77, dtype: float64
#+end_example


#+begin_src python :session py1 :results none
  
transformers = {'MinMaxScaler': {'features': ['sign_return']},
'StandardScaler_1': {'features': ['EMA', 'MA', 'Std', 'Ret', 'OC']},
'RobustScaler': {'features': ['momentum', 'volume', 'HL']},
'StandardScaler_2': {'features': pa_volfeatures},
'StandardScaler_3': {'features': pa_features}
}

columns = ml4qf.transformers.build_transformation(df_, transformers)
columns_validation = ml4qf.transformers.build_transformation(df_, transformers)
ct = sklearn.compose.ColumnTransformer(columns, remainder='passthrough')
#ct_validation = sklearn.compose.ColumnTransformer(columns, remainder='passthrough')

#+end_src

*** Split data
#+begin_src python :session py1 :results output
  Xtrain, Xtest = train_test_split(df_.to_numpy(), train_size=0.8, shuffle=False)
  len_train = len(Xtrain)
  len_test = len(Xtest)
  df_train = df_.iloc[:len_train, :]
  df_test = df_.iloc[len_train:, :]
  Xtrain_scaled = ct.fit_transform(df_train)
  Xtrain_scaled = ml4qf.transformers.swap_features(Xtrain_scaled, df_train, ct)
  Xtest_scaled = ct.transform(df_test)
  Xtest_scaled = ml4qf.transformers.swap_features(Xtest_scaled, df_test, ct)
  df_train_scaled = ml4qf.transformers.scale_df(df_train, columns_validation)
  assert (Xtrain_scaled == df_train_scaled.to_numpy()).all(), "scaling failed"
  #Xtrain_scaled = ct.transform(Xtrain)

#+end_src

#+RESULTS:

** SOM

#+begin_src python :session py1
  ########
  # def set_seeds(seed=42): 
  #     random.seed(seed)
  #     np.random.seed(seed)
  #     tf.random.set_seed(seed)

  ml4qf.utils.set_seeds(['np.random'])
  som_size = 50
  som_num_features = Xtrain_scaled.shape[1]
  som_model = minisom.MiniSom(som_size, som_size, som_num_features, sigma=1.5, learning_rate=0.1, 
  neighborhood_function='gaussian', random_seed=42)
  # x, y, input_len, sigma=1.0, learning_rate=0.5,
  #                  decay_function=asymptotic_decay,
  #                  neighborhood_function='gaussian', topology='rectangular',
  #                  activation_distance='euclidean', random_seed=None)
  som_model.pca_weights_init(Xtrain_scaled)
  som_model.train(Xtrain_scaled, 10000, verbose=True)

  W = som_model.get_weights()
  som_labels0, target_name = ml4qf.predictors.model_som.Model.feature_selection(W, labels=df_.columns, target_index = -1, a = 0.08)

  #assert target_name = 'target', "targets do not coincide after som" 
  #dftrain_reduced = df_train[som_labels]
  #dftest_reduced = df_test[som_labels]
  som_labels0
#+end_src

#+RESULTS:
| ABER_ZG_5_15 | HL_ | sign_return_7d | momentum_2d | UI_14 | VOLUME_EMA_5 |

#+begin_src python :session py1 :results output
import ml4qf.predictors.model_som
som_size = 50
som_obj = ml4qf.predictors.model_som.Model(som_size, som_size, Xtrain_scaled, sigma=1.5, learning_rate=0.1, 
neighborhood_function='gaussian', num_iter=10000, random_seed=42)
som_labels = som_obj.iterate_som_selection(min_num_features=30, labels=list(df_train.columns), a_range=[0.01, 0.03, 0.05, 0.08, 0.1, 0.2], num_iterations=30)
print(som_labels)
#+end_src

#+RESULTS:
: Total number of iterations: 9
: ['Ret_5d', 'sign_return_7d', 'OC_', 'ABER_XG_5_15', 'VOLUME_EMA_5', 'momentum_15d', 'sign_return_6d', 'BBP_5_2.0', 'KCLe_20_2', 'OHLC4', 'sign_return_2d', 'ABER_ATR_5_15', 'VOLUME_EMA_10', 'THERMOl_20_2_0.5', 'TRUERANGE_1', 'momentum_8d', 'momentum_5d', 'UI_14', 'Ret_1d', 'Std_20d', 'momentum_23d', 'MASSI_9_25', 'Std_30d', 'momentum_2d', 'sign_return_5d', 'ATRr_14', 'HL_', 'EMA_5d', 'THERMOma_20_2_0.5', 'sign_return_3d', 'PDIST', 'volume_']


#+begin_src python :session py1 :results file
  # for i, f in enumerate(feature_names):
  #     plt.subplot(3, 3, i+1)
  #     plt.title(f)
  #     plt.pcolor(W[:,:,i].T, cmap='coolwarm')
  #     plt.xticks(np.arange(size+1))
  #     plt.yticks(np.arange(size+1))
  # plt.tight_layout()
  # plt.show()
  #+begin_src python :session py1 :results file
  fig1_path= img_dir +'/som.png'
  fig1 = px.imshow(W[:,:,0].T)
  fig1.layout.height = 600
  fig1.layout.width = 600
  fig1.write_image(fig1_path)
  fig1_path
#+end_src

#+RESULTS:
[[file:./img/_EADSY_2014-10-02_2019-10-01/som.png]]

#+end_src

*** Reduced model

#+begin_src python :session py1 :results output
  index_reducedlabels = [df_train.columns.get_loc(i) for i in som_labels]
  dftrain_reduced = df_train[som_labels]
  dftest_reduced = df_test[som_labels]
  assert (dftrain_reduced.to_numpy() == Xtrain[:, index_reducedlabels]).all(), "Reduced matrix not maching dimensions"
  Xtrain_reduced = Xtrain_scaled[:, index_reducedlabels]
  Xtest_reduced = Xtest_scaled[:, index_reducedlabels]
  #Xtest_reduced = Xtest_scaled[:, index_reducedlabels]
#+end_src

#+RESULTS:

* Base line model

#+begin_src python :session py1

  y = df_train['target'].to_numpy()
  layers_dict = dict()
  layers_dict['LSTM'] = dict(units=5, activation = 'relu', return_sequences=False, name='LSTM')
  layers_dict['Dense'] = dict(units=1, name='Output')
  layers_tuple = ml4qf.utils.dict2tuple(layers_dict)
  base_model = model_keras.Model(keras_model='Sequential', layers=layers_tuple, seqlen=10
                                 optimizer_name='adam', loss_name='binary_crossentropy', metrics=None,
                                 optimizer_sett=None, compile_sett=None, loss_sett=None)
  base_model.fit(Xtrain_reduced, y)

#+end_src

#+RESULTS:


** Classification

#+begin_src python :session py1
  y_test = df_test.target.to_numpy()
  ypred_basemodel = base_model.predict(X_test_reduced)
  sklearn.metrics.classification_report(y_test, ypred_basemodel)
#+end_src

#+RESULTS:
| 236 | 32 |

#+begin_src python  :session py_lstm :results none
# summary
basemodel._model.summary()
#+end_src
* Cross validation

** UMAP model


** LSTM model


** Optimisation

#+begin_src python :session py1
  umap_model = umap.UMAP()
  lstm_model = model_keras.Model_binary()
  pipe = sklearn.pipeline.Pipeline([('umap',umap_model),
                                    ('lstm', lstm_model)])
  pipe.get_params()

#+end_src

#+RESULTS:
| memory | : | hline | steps | : | ((umap UMAP nil) (lstm Model_binary nil)) | verbose | : | False | umap | : | UMAP | nil | lstm | : | Model_binary | nil | umap__a | : | hline | umap__angular_rp_forest | : | False | umap__b | : | hline | umap__dens_frac | : | 0.3 | umap__dens_lambda | : | 2.0 | umap__dens_var_shift | : | 0.1 | umap__densmap | : | False | umap__disconnection_distance | : | hline | umap__force_approximation_algorithm | : | False | umap__init | : | spectral | umap__learning_rate | : | 1.0 | umap__local_connectivity | : | 1.0 | umap__low_memory | : | True | umap__metric | : | euclidean | umap__metric_kwds | : | hline | umap__min_dist | : | 0.1 | umap__n_components | : | 2 | umap__n_epochs | : | hline | umap__n_jobs | : | -1 | umap__n_neighbors | : | 15 | umap__negative_sample_rate | : | 5 | umap__output_dens | : | False | umap__output_metric | : | euclidean | umap__output_metric_kwds | : | hline | umap__precomputed_knn | : | (None None None) | umap__random_state | : | hline | umap__repulsion_strength | : | 1.0 | umap__set_op_mix_ratio | : | 1.0 | umap__spread | : | 1.0 | umap__target_metric | : | categorical | umap__target_metric_kwds | : | hline | umap__target_n_neighbors | : | -1 | umap__target_weight | : | 0.5 | umap__tqdm_kwds | : | hline | umap__transform_mode | : | embedding | umap__transform_queue_size | : | 4.0 | umap__transform_seed | : | 42 | umap__unique | : | False | umap__verbose | : | False | lstm__keras_model | : | Sequential | lstm__layers | : | nil | lstm__seqlen | : | 0 | lstm__optimizer_name | : | adam | lstm__optimizer_sett | : | hline | lstm__compile_sett | : | hline | lstm__loss_sett | : | hline | lstm__loss_name | : | binary_crossentropy | lstm__metrics | : | hline | lstm__timeseries_sett | : | hline |


#+begin_src python :session py1 :results output
  searcher_name = 'RandomSearchCV'
  layers_hyper = []
  ###########
  layers_dict = dict()
  layers_dict['LSTM_1'] = dict(units=100, activation = 'elu', name='LSTM1')
  layers_dict['Dense_1'] = dict(units=1, activation='sigmoid', name='Output')
  layers_tuple = ml4qf.utils.dict2tuple(layers_dict)
  layers_hyper.append(layers_tuple)
  #####################
  layers_dict = dict()
  layers_dict['LSTM_1'] = dict(units=50, activation = 'elu', return_sequences=True, name='LSTM1')
  layers_dict['LSTM_2'] = dict(units=50, activation = 'elu', return_sequences=False, name='LSTM2')
  layers_dict['Dense_1'] = dict(units=1, activation='sigmoid', name='Output')
  layers_tuple = ml4qf.utils.dict2tuple(layers_dict)
  layers_hyper.append(layers_tuple)
  ############
  layers_dict = dict()
  layers_dict['LSTM_1'] = dict(units=50, activation = 'elu', return_sequences=True, name='LSTM1')
  layers_dict['Dropout_1'] = dict(rate=0.3, name='Drouput1')
  layers_dict['LSTM_2'] = dict(units=25, activation = 'elu', return_sequences=True, name='LSTM2')
  layers_dict['Dropout_2'] = dict(rate=0.3, name='Drouput2')
  layers_dict['LSTM_3'] = dict(units=25, activation = 'elu', return_sequences=False, name='LSTM3')
  layers_dict['Dense_1'] = dict(units=1, activation='sigmoid', name='Output')
  layers_tuple = ml4qf.utils.dict2tuple(layers_dict)
  layers_hyper.append(layers_tuple)
  #####################

  ###########
  hyper_grid = {#'umap':dict(n_neighbors=[5, 15, 30, 50, 100],
                #            n_components=[3, 8, 15, 30],
                #            min_dist=[0.05, 0.1, 0.4, 0.75],
                #            random_state=42),
                'umap':dict(n_neighbors=[30, 50],    
                            n_components=[3, 2],         
                            min_dist=[0.05, 0.2],     
                            random_state=42),                    
                'lstm':dict(seqlen=[10, 25],
                            layers=layers_hyper,
                            optimizer_name=[])
                }
  searcher_settings = {'scoring':'f1',
                       'n_iter':25,
                       'verbose': True}
  cv_name = 'TimeSeriesSplit'
  cv_settings = {'n_splits': 3}
  #_hypertuning1 = HyperTuning(pipe, searcher_name, searcher_settings,
  #                           hyper_grid, cv_name, cv_settings)
  #hypertuning1 = _hypertuning1()
  #hypertuning1.fit(df_train.to_numpy())

#+end_src

#+RESULTS:

* Implementation

| Name | Description | Value |
|      |             |       |


