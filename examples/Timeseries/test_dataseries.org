#+PROPERTY: header-args :tangle ./test_dataseries.py :mkdirp yes
* House keeping
#+begin_src elisp :results none :tangle no :exports none
  (add-to-list 'org-structure-template-alist
  '("sp" . "src python :session py1"))
  (add-to-list 'org-structure-template-alist
  '("se" . "src elisp"))

  (setq org-confirm-babel-evaluate nil)
  (pyvenv-workon "ml4qf")
  (require 'org-tempo)  
#+end_src

* Import libraries
#+BEGIN_SRC python :session py1 :results output silent :exports none

  ################################
  # Import libraries and modules #
  ################################

  import numpy as np
  import pathlib
  import yfinance as yf
  from tabulate import tabulate
  # from umap import UMAP
  # import matplotlib.pyplot as plt
  # from mpl_toolkits.mplot3d import Axes3D
  # import matplotlib
  # matplotlib.rcParams['figure.dpi'] = 80

  import minisom
  import umap
  from sklearn.model_selection import train_test_split
  import sklearn.metrics
  import scipy.optimize
  import sklearn.compose
  import sklearn.pipeline
  #from scikeras.wrappers import KerasClassifier
  import tensorflow.keras.utils
  import plotly.express as px
  import scipy.stats
  import pandas as pd
  import pandas_ta as ta
  import pickle
  import ml4qf
  import ml4qf.utils
  import ml4qf.predictors.model_som
  import ml4qf.collectors.financial_features
  import ml4qf.transformers
  import ml4qf.predictors.model_keras as model_keras
  import ml4qf.predictors.model_tuning
  from ml4qf.predictors.models import model_factory  
  import config
  import importlib
  importlib.reload(config)
  import matplotlib.pyplot as plt

#+END_SRC

* Feature engineering
:PROPERTIES:
:header-args: :exports none
:END:
[[https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/]]

#+begin_src python :session py1 :results file
  img_dir = "./img/time_series.png"
  tensorflow.keras.utils.set_random_seed(config.RANDOM_SEED)
  df = pd.read_csv('./dataseries.csv', usecols=[1], engine='python')
  dataset = df.values
  dataset = dataset.astype('float32')
  ########################
  fig1 = plt.figure()
  ax = fig1.add_axes([0.1, 0.1, 0.8, 0.8])
  ax.plot(dataset)
  plt.savefig(img_dir)
  img_dir
#+end_src

#+RESULTS:
[[file:./img/time_series.png]]

** Feature scaling

#+begin_src python :session py1 :results none
  transformers = {'MinMaxScaler': {'features': ['Passengers'],
                                   'settings': dict(feature_range=(0, 1))}
                 }
  ct = ml4qf.transformers.Build_ColumnTransformer(df, transformers)(remainder='passthrough')
  dataset1 = ct.fit_transform(df)
  y = df['Passengers'].shift(-1)
  y1 = dataset1[1:,0]
  dataset1 = dataset1[:-1]
  #dataset
  # df['y'] = df['Passengers'].shift(-1)

  # ct = sklearn.compose.ColumnTransformer(columns, remainder='passthrough')
  # ct_validation = sklearn.compose.ColumnTransformer(columns, remainder='passthrough')
#+end_src

*** Split data
#+begin_src python :session py1 :results output
  Xtrain, Xtest = train_test_split(dataset1,
                                   train_size=config.TRAIN_SIZE,
                                   shuffle=False)
  ytrain, ytest = train_test_split(y1,
                                   train_size=config.TRAIN_SIZE,
                                   shuffle=False)

  SEQ_LEN = 1
#+end_src

#+RESULTS:


* LSTM design

** Base line model

#+begin_src python :session py1
  #######################
  base_model = model_factory('keras', 'Model', None, config.lstm)

  #base_model.set_params(**winner)
  base_model.fit(Xtrain, ytrain, epochs=100, verbose=2)

  # summary
  #base_model._model.summary()

#+end_src

#+RESULTS:
: Model(batch_size=1,
:       layers=(('LSTM_1', (('units', 4), ('name', 'LSTM1'))),
:               ('Dense_1', (('units', 1), ('name', 'Output')))),
:       loss_name='mean_squared_error',
:       metrics=['accuracy', 'binary_accuracy', 'mse'], seqlen=1)

*** Classification
#+begin_src python :session py1 :results output
  ypred_basemodel = base_model.predict(Xtest)#.reshape(48)
  test_report = sklearn.metrics.classification_report(ytest.reshape((48, 1)), 
                                                      ypred_basemodel, output_dict=True)
  dftest_report = pd.DataFrame(test_report).transpose()
  print(dftest_report)

#+end_src


#+begin_src python :session py1
  ypred_basemodeltrain = base_model.predict(Xtrain_reduced, y_train)#.reshape(len(y_train[SEQ_LEN-1:]))
  train_report = sklearn.metrics.classification_report(base_model.ypred_generated_,
                                                       ypred_basemodeltrain, output_dict=True)
  dftrain_report = pd.DataFrame(train_report).transpose()
  print(dftrain_report)

#+end_src

#+RESULTS:
: None

* Code

#+begin_src python :session py1
  # LSTM for international airline passengers problem with regression framing
  import numpy as np
  import matplotlib.pyplot as plt
  from pandas import read_csv
  import math
  import tensorflow as tf
  from tensorflow.keras.models import Sequential
  from tensorflow.keras.layers import Dense
  from tensorflow.keras.layers import LSTM
  from sklearn.preprocessing import MinMaxScaler
  from sklearn.metrics import mean_squared_error
  # convert an array of values into a dataset matrix
  def create_dataset(dataset, look_back=1):
          dataX, dataY = [], []
          for i in range(len(dataset)-look_back-1):
                  a = dataset[i:(i+look_back), 0]
                  dataX.append(a)
                  dataY.append(dataset[i + look_back, 0])
          return np.array(dataX), np.array(dataY)
  # fix random seed for reproducibility
  tf.random.set_seed(7)
  # load the dataset
  dataframe = read_csv('./dataseries.csv', usecols=[1], engine='python')
  dataset = dataframe.values
  dataset = dataset.astype('float32')
  # normalize the dataset
  scaler = MinMaxScaler(feature_range=(0, 1))
  dataset = scaler.fit_transform(dataset)
  # split into train and test sets
  train_size = int(len(dataset) * 0.67)
  test_size = len(dataset) - train_size
  train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]
  # reshape into X=t and Y=t+1
  look_back = 1
  trainX, trainY = create_dataset(train, look_back)
  testX, testY = create_dataset(test, look_back)
  # reshape input to be [samples, time steps, features]
  trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))
  testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))
  # create and fit the LSTM network
  model = Sequential()
  model.add(LSTM(4, input_shape=(1, look_back)))
  model.add(Dense(1))
  model.compile(loss='mean_squared_error', optimizer='adam')
  model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)
  # make predictions
  trainPredict = model.predict(trainX)
  testPredict = model.predict(testX)
  # invert predictions
  trainPredict = scaler.inverse_transform(trainPredict)
  trainY = scaler.inverse_transform([trainY])
  testPredict = scaler.inverse_transform(testPredict)
  testY = scaler.inverse_transform([testY])
  # calculate root mean squared error
  trainScore = np.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))
  print('Train Score: %.2f RMSE' % (trainScore))
  testScore = np.sqrt(mean_squared_error(testY[0], testPredict[:,0]))
  print('Test Score: %.2f RMSE' % (testScore))
  # shift train predictions for plotting
  trainPredictPlot = np.empty_like(dataset)
  trainPredictPlot[:, :] = np.nan
  trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict
  # shift test predictions for plotting
  testPredictPlot = np.empty_like(dataset)
  testPredictPlot[:, :] = np.nan
  testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict
  # plot baseline and predictions
  plt.plot(scaler.inverse_transform(dataset))
  plt.plot(trainPredictPlot)
  plt.plot(testPredictPlot)
  plt.show()
#+end_src

#+RESULTS:
: None
